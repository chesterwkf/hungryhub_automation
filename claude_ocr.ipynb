{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Menu Items Extraction and Menu Categorisation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 22:33:04,057 - INFO - ===== MENU ITEM EXTRACTION AND PRICE CATEGORIZATION =====\n",
      "2025-04-25 22:33:04,062 - INFO - Processing menu images from folder: /Users/Cwkf_89/Documents/GitHub/hungryhub_automation/test_menus/test_menu2\n",
      "2025-04-25 22:33:04,067 - INFO - Target number of price categories: 4\n",
      "2025-04-25 22:33:04,093 - INFO - Found 11 images to process in folder: ./test_menus/test_menu2\n",
      "2025-04-25 22:33:04,094 - INFO - \n",
      "--- Processing image 1/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0008.jpg ---\n",
      "2025-04-25 22:33:04,108 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0008.jpg\n",
      "2025-04-25 22:33:04,115 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:08,014 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:08,016 - INFO - Received response from Claude. Content length: 439 characters.\n",
      "2025-04-25 22:33:08,017 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0008.jpg. Parsing content...\n",
      "2025-04-25 22:33:08,017 - INFO - Parsing 5 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:08,018 - INFO - Parsing complete. Successfully extracted 5 items.\n",
      "2025-04-25 22:33:08,018 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:08,018 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:08,019 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:08,019 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:08,020 - INFO - Parsed 5 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0008.jpg.\n",
      "2025-04-25 22:33:08,020 - INFO - Combined total unique items so far: 5\n",
      "2025-04-25 22:33:08,020 - INFO - \n",
      "--- Processing image 2/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0009.jpg ---\n",
      "2025-04-25 22:33:08,028 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0009.jpg\n",
      "2025-04-25 22:33:08,034 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:10,658 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:10,662 - INFO - Received response from Claude. Content length: 277 characters.\n",
      "2025-04-25 22:33:10,663 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0009.jpg. Parsing content...\n",
      "2025-04-25 22:33:10,663 - INFO - Parsing 4 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:10,664 - INFO - Duplicate item name 'Sweet and Sour Soup Phuket Style with Trevally Fish' found with different price/category. Storing as 'Sweet and Sour Soup Phuket Style with Trevally Fish (1)'.\n",
      "2025-04-25 22:33:10,664 - INFO - Parsing complete. Successfully extracted 4 items.\n",
      "2025-04-25 22:33:10,665 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:10,665 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:10,666 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:10,667 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:10,667 - INFO - Parsed 4 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0009.jpg.\n",
      "2025-04-25 22:33:10,668 - INFO - Combined total unique items so far: 9\n",
      "2025-04-25 22:33:10,668 - INFO - \n",
      "--- Processing image 3/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0007.jpg ---\n",
      "2025-04-25 22:33:10,680 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0007.jpg\n",
      "2025-04-25 22:33:10,690 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:15,252 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:15,257 - INFO - Received response from Claude. Content length: 637 characters.\n",
      "2025-04-25 22:33:15,258 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0007.jpg. Parsing content...\n",
      "2025-04-25 22:33:15,258 - INFO - Parsing 10 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:15,259 - INFO - Exact duplicate item found: 'Stir Fried Sea Bass Meat with Butter Melon'. Skipping.\n",
      "2025-04-25 22:33:15,260 - INFO - Parsing complete. Successfully extracted 9 items.\n",
      "2025-04-25 22:33:15,261 - INFO - Extraction rate: 90.0% of non-empty lines.\n",
      "2025-04-25 22:33:15,261 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:15,262 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:15,262 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:15,263 - INFO - Parsed 9 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0007.jpg.\n",
      "2025-04-25 22:33:15,263 - INFO - Combined total unique items so far: 18\n",
      "2025-04-25 22:33:15,264 - INFO - \n",
      "--- Processing image 4/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0012.jpg ---\n",
      "2025-04-25 22:33:15,277 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0012.jpg\n",
      "2025-04-25 22:33:15,284 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:18,845 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:18,848 - INFO - Received response from Claude. Content length: 282 characters.\n",
      "2025-04-25 22:33:18,849 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0012.jpg. Parsing content...\n",
      "2025-04-25 22:33:18,849 - INFO - Parsing 6 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:18,850 - INFO - Parsing complete. Successfully extracted 6 items.\n",
      "2025-04-25 22:33:18,850 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:18,851 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:18,851 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:18,851 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:18,852 - INFO - Parsed 6 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0012.jpg.\n",
      "2025-04-25 22:33:18,852 - INFO - Combined total unique items so far: 24\n",
      "2025-04-25 22:33:18,853 - INFO - \n",
      "--- Processing image 5/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0006.jpg ---\n",
      "2025-04-25 22:33:18,865 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0006.jpg\n",
      "2025-04-25 22:33:18,878 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:22,919 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:22,923 - INFO - Received response from Claude. Content length: 694 characters.\n",
      "2025-04-25 22:33:22,924 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0006.jpg. Parsing content...\n",
      "2025-04-25 22:33:22,925 - INFO - Parsing 12 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:22,925 - INFO - Parsing complete. Successfully extracted 12 items.\n",
      "2025-04-25 22:33:22,926 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:22,926 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:22,927 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:22,927 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:22,928 - INFO - Parsed 12 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0006.jpg.\n",
      "2025-04-25 22:33:22,928 - INFO - Combined total unique items so far: 36\n",
      "2025-04-25 22:33:22,928 - INFO - \n",
      "--- Processing image 6/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0010.jpg ---\n",
      "2025-04-25 22:33:22,941 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0010.jpg\n",
      "2025-04-25 22:33:22,950 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:25,463 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:25,467 - INFO - Received response from Claude. Content length: 250 characters.\n",
      "2025-04-25 22:33:25,469 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0010.jpg. Parsing content...\n",
      "2025-04-25 22:33:25,469 - INFO - Parsing 5 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:25,470 - INFO - Duplicate item name 'Hot and Spicy Soup' found with different price/category. Storing as 'Hot and Spicy Soup (1)'.\n",
      "2025-04-25 22:33:25,471 - INFO - Parsing complete. Successfully extracted 5 items.\n",
      "2025-04-25 22:33:25,471 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:25,471 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:25,472 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:25,472 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:25,472 - INFO - Parsed 5 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0010.jpg.\n",
      "2025-04-25 22:33:25,472 - WARNING - Item 'Hot and Spicy Soup' from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0010.jpg differs from previous entry. Storing as 'Hot and Spicy Soup (Img 6)'. Old: P=179.0, C='THB Hot and Spicy Soup'. New: P=350.0, C='Main Course'.\n",
      "2025-04-25 22:33:25,473 - INFO - Combined total unique items so far: 41\n",
      "2025-04-25 22:33:25,473 - INFO - \n",
      "--- Processing image 7/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0004.jpg ---\n",
      "2025-04-25 22:33:25,482 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0004.jpg\n",
      "2025-04-25 22:33:25,488 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:29,018 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:29,020 - INFO - Received response from Claude. Content length: 424 characters.\n",
      "2025-04-25 22:33:29,022 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0004.jpg. Parsing content...\n",
      "2025-04-25 22:33:29,023 - INFO - Parsing 6 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:29,023 - INFO - Parsing complete. Successfully extracted 6 items.\n",
      "2025-04-25 22:33:29,023 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:29,024 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:29,024 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:29,025 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:29,025 - INFO - Parsed 6 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0004.jpg.\n",
      "2025-04-25 22:33:29,025 - INFO - Combined total unique items so far: 47\n",
      "2025-04-25 22:33:29,026 - INFO - \n",
      "--- Processing image 8/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0005.jpg ---\n",
      "2025-04-25 22:33:29,037 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0005.jpg\n",
      "2025-04-25 22:33:29,047 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:35,058 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:35,060 - INFO - Received response from Claude. Content length: 1040 characters.\n",
      "2025-04-25 22:33:35,061 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0005.jpg. Parsing content...\n",
      "2025-04-25 22:33:35,061 - INFO - Parsing 14 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:35,062 - INFO - Parsing complete. Successfully extracted 14 items.\n",
      "2025-04-25 22:33:35,063 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:35,063 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:35,063 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:35,064 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:35,064 - INFO - Parsed 14 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0005.jpg.\n",
      "2025-04-25 22:33:35,065 - INFO - Combined total unique items so far: 61\n",
      "2025-04-25 22:33:35,065 - INFO - \n",
      "--- Processing image 9/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0011.jpg ---\n",
      "2025-04-25 22:33:35,077 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0011.jpg\n",
      "2025-04-25 22:33:35,085 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:39,669 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:39,670 - INFO - Received response from Claude. Content length: 755 characters.\n",
      "2025-04-25 22:33:39,671 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0011.jpg. Parsing content...\n",
      "2025-04-25 22:33:39,671 - INFO - Parsing 12 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:39,671 - INFO - Parsing complete. Successfully extracted 12 items.\n",
      "2025-04-25 22:33:39,672 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:39,672 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:39,672 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:39,673 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:39,673 - INFO - Parsed 12 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0011.jpg.\n",
      "2025-04-25 22:33:39,673 - INFO - Combined total unique items so far: 73\n",
      "2025-04-25 22:33:39,674 - INFO - \n",
      "--- Processing image 10/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0002.jpg ---\n",
      "2025-04-25 22:33:39,682 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0002.jpg\n",
      "2025-04-25 22:33:39,688 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:44,301 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:44,305 - INFO - Received response from Claude. Content length: 640 characters.\n",
      "2025-04-25 22:33:44,305 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0002.jpg. Parsing content...\n",
      "2025-04-25 22:33:44,306 - INFO - Parsing 9 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:44,306 - INFO - Duplicate item name 'Southern Curry with Trevally Fish without Coconut Milk' found with different price/category. Storing as 'Southern Curry with Trevally Fish without Coconut Milk (1)'.\n",
      "2025-04-25 22:33:44,307 - INFO - Parsing complete. Successfully extracted 9 items.\n",
      "2025-04-25 22:33:44,307 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:44,308 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:44,309 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:44,309 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:44,310 - INFO - Parsed 9 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0002.jpg.\n",
      "2025-04-25 22:33:44,310 - INFO - Combined total unique items so far: 82\n",
      "2025-04-25 22:33:44,310 - INFO - \n",
      "--- Processing image 11/11: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0003.jpg ---\n",
      "2025-04-25 22:33:44,322 - INFO - Encoding image: 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0003.jpg\n",
      "2025-04-25 22:33:44,329 - INFO - Sending request to Claude API...\n",
      "2025-04-25 22:33:48,268 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 22:33:48,271 - INFO - Received response from Claude. Content length: 202 characters.\n",
      "2025-04-25 22:33:48,272 - INFO - Text extraction successful for 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0003.jpg. Parsing content...\n",
      "2025-04-25 22:33:48,272 - INFO - Parsing 5 non-empty lines from Claude output.\n",
      "2025-04-25 22:33:48,273 - INFO - Parsing complete. Successfully extracted 5 items.\n",
      "2025-04-25 22:33:48,273 - INFO - Extraction rate: 100.0% of non-empty lines.\n",
      "2025-04-25 22:33:48,273 - INFO - Items marked unclear by Claude or parser: 0\n",
      "2025-04-25 22:33:48,273 - INFO - Items assigned default 'Uncategorized' category: 0\n",
      "2025-04-25 22:33:48,274 - INFO - Average confidence score for extracted items: 100.0%\n",
      "2025-04-25 22:33:48,274 - INFO - Parsed 5 items from 24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0003.jpg.\n",
      "2025-04-25 22:33:48,274 - INFO - Combined total unique items so far: 87\n",
      "2025-04-25 22:33:48,274 - INFO - \n",
      "===== Image Processing Summary =====\n",
      "2025-04-25 22:33:48,275 - INFO - Total items parsed across all images (before deduplication/variants): 87\n",
      "2025-04-25 22:33:48,275 - INFO - Final unique items/variants stored: 87\n",
      "2025-04-25 22:33:48,275 - INFO - \n",
      "Items Parsed Per Image:\n",
      "2025-04-25 22:33:48,275 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0008.jpg: 5 items\n",
      "2025-04-25 22:33:48,276 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0009.jpg: 4 items\n",
      "2025-04-25 22:33:48,276 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0007.jpg: 9 items\n",
      "2025-04-25 22:33:48,276 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0012.jpg: 6 items\n",
      "2025-04-25 22:33:48,277 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0006.jpg: 12 items\n",
      "2025-04-25 22:33:48,277 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0010.jpg: 5 items\n",
      "2025-04-25 22:33:48,278 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0004.jpg: 6 items\n",
      "2025-04-25 22:33:48,278 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0005.jpg: 14 items\n",
      "2025-04-25 22:33:48,278 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0011.jpg: 12 items\n",
      "2025-04-25 22:33:48,279 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0002.jpg: 9 items\n",
      "2025-04-25 22:33:48,280 - INFO -   24-04-26_กับภูเก็ต_Menu book A3_Revise02_AW Only_page-0003.jpg: 5 items\n",
      "2025-04-25 22:33:48,281 - INFO - Overall average extraction confidence: 100.0%\n",
      "2025-04-25 22:33:48,281 - INFO - Using requested number of price categories: 4\n",
      "2025-04-25 22:33:48,282 - INFO - \n",
      "--- Categorizing All Extracted Items by Price ---\n",
      "2025-04-25 22:33:48,282 - INFO - \n",
      "Price range for categorization: $18.00 to $495.00 (Spread: $477.00)\n",
      "2025-04-25 22:33:48,282 - INFO - Large price range detected (range/min > 3.0) - using adaptive (percentile-based) categorization.\n",
      "2025-04-25 22:33:48,283 - INFO - Adaptive category price boundaries (Min price for Cat A, B, C...): ['>$268.00', '>$179.00', '>$150.00']\n",
      "2025-04-25 22:33:48,283 - INFO - \n",
      "--- Final Item Distribution by Price Category ---\n",
      "2025-04-25 22:33:48,283 - INFO - Category A: 22 items. Actual price range: $268.00 - $495.00\n",
      "2025-04-25 22:33:48,285 - INFO - Category B: 24 items. Actual price range: $179.00 - $250.00\n",
      "2025-04-25 22:33:48,285 - INFO - Category C: 28 items. Actual price range: $150.00 - $175.00\n",
      "2025-04-25 22:33:48,285 - INFO - Category D: 13 items. Actual price range: $18.00 - $149.00\n",
      "2025-04-25 22:33:48,286 - INFO - \n",
      "========== FINAL MENU ITEMS BY PRICE CATEGORY ==========\n",
      "2025-04-25 22:33:48,287 - INFO - \n",
      "Saving results to: /Users/Cwkf_89/Documents/GitHub/hungryhub_automation/categorized_menu_items.txt\n",
      "2025-04-25 22:33:48,289 - INFO - Results successfully saved to categorized_menu_items.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Category A ($268.00 - $495.00) -----\n",
      "22 items:\n",
      "  $495.00 - Sweet and Sour Soup Phuket Style with Trevally Fish (1) (THB Hot and Spicy Soup)\n",
      "  $490.00 - Deep Fried Prawns' Meat with Fried Curry Paste ($590 Stir-Fried and Deep-Fried Dishes)\n",
      "  $490.00 - Fried Trevally Fish Meat Mixed with Curry Paste (/$590.00 Main Course)\n",
      "  $455.00 - Sweet and Sour Soup Phuket Style with Trevally Fish (/599 THB Hot and Spicy Soup)\n",
      "  $455.00 - Southern Curry with Trevally Fish without Coconut Milk (1) (/$599.00 Main Course)\n",
      "  $450.00 - Hot and Spicy Soup (1) (Main Course)\n",
      "  $450.00 - Chilli Paste Recommended Dish ฉีดเนื้อพริกสด ฉันต้านาน (Chilli Paste Dishes)\n",
      "  $439.00 - Stir Fried and Deep-Fried Dishes (Baht / 540 Baht Uncategorized)\n",
      "  $400.00 - Sliced Fish Meat Marinated with Tamarind Juice,Lemon Grass, Galangal, Basil and Mint ปลาซั่มย้างสมพะพริก (/550 บาท Specialty Dish)\n",
      "  $390.00 - Stir Fried Slender Fish Egg with Bitter Bean (Main Course)\n",
      "  $350.00 - Hot and Spicy Soup (Img 6) (Main Course)\n",
      "  $299.00 - Stir Fried Sea Bass Meat with Butter Melon (Baht Main Course)\n",
      "  $299.00 - Yellow Curry (to coconut milk) with bamboo and Sea bass (Main Course)\n",
      "  $295.00 - Stewed Pork Belly with Pineapple and Herbs หมูฮ่องเส้า (บาท Specialty Dish)\n",
      "  $295.00 - Spicy Shrimp Fried with Bitter Bean (Baht Main Course)\n",
      "  $295.00 - Fried Sea Bass Meat with Chili And Salt (Stir-Fried and Deep-Fried Dishes)\n",
      "  $295.00 - Fried Sea Bass Meat with Crispy (Stir-Fried and Deep-Fried Dishes)\n",
      "  $295.00 - Fried Sea Bass Meat with Chili (Stir-Fried and Deep-Fried Dishes)\n",
      "  $295.00 - Fried Sea Bass Meat with Crispy Basil (Stir-Fried and Deep-Fried Dishes)\n",
      "  $295.00 - Steamed Pork Belly with Pineapple and Herbs (Main Course)\n",
      "  $269.00 - She fried Shrimp Paste Served with Fried Crispy Salted Fish (Chilli Paste Dishes)\n",
      "  $268.00 - Stir Fried Dried Shrimp Paste (Baht Main Course)\n",
      "\n",
      "----- Category B ($179.00 - $250.00) -----\n",
      "24 items:\n",
      "  $250.00 - Shrimp Paste Mixed with Fried Salted Fish (Chilli Paste Dishes)\n",
      "  $250.00 - เบญจรงค์ Fried Shrimp Coated with Flour Milk Seasoned with Curry Powder Served with Sweet Chili Sauce (Appetizer)\n",
      "  $250.00 - หอยทอดกระเทียม Fried Shrimp with Garlic (Appetizer)\n",
      "  $250.00 - เอี๊ยะ Curry Paste in Coconut Milk with Seafood Served on Siding Dish (Appetizer)\n",
      "  $230.00 - Shrimp Paste Mixed with Fried Pork Belly (Main Course)\n",
      "  $195.00 - บูดูกะทะ Yellow-Stripe Trevally Fried with Turmeric (Appetizer)\n",
      "  $195.00 - บูดูทอดมะพร้าว Shrimp Tails fried with turmeric and coconut (Appetizer)\n",
      "  $195.00 - Fried Rice with Shrimped Pork Belly and Phuket Pineapple (Main Course)\n",
      "  $195.00 - Fried Rice with Shrimped Pork Belly (Main Course)\n",
      "  $195.00 - Fried Rice with Grilled Fresh Soft Shell Crab (Main Course)\n",
      "  $195.00 - Fried Rice with Grilled Fried Soft Shell Crab (Main Course)\n",
      "  $190.00 - Boiled Catfish with Turmeric (Soup Dish)\n",
      "  $190.00 - Boiled Catfish with Lemon Grass (Soup Dish)\n",
      "  $190.00 - เมี่ยงมะหวด Steamed Fresh Meat in Coconut Milk Boiling on Togethers and Wrapped with Banana Leaf (Appetizer)\n",
      "  $190.00 - Fried Prawn with Garlic and Pepper (Main Course)\n",
      "  $190.00 - Fish Fillet with Lemon Grass and Fried Sea Bass (Main Course)\n",
      "  $189.00 - ยำสับปะหลกบ้านนอก Pineapple Salad with Boiled Shrimp (Phuket Style) (Appetizer)\n",
      "  $185.00 - Fried Fish with Curry Powder (Other Menu)\n",
      "  $180.00 - Shrimp Paste Mixed with Fried Anchovoy (Chilli Paste Dishes)\n",
      "  $180.00 - บูดูทอดขม Shrimp Fried with Intestine Seasoning and Crispy Fried (Appetizer)\n",
      "  $180.00 - Spicy Rice Salad with Shrimp Paste and Roasted Coconut (Main Course)\n",
      "  $179.00 - Hot and Spicy Soup (THB Hot and Spicy Soup)\n",
      "  $179.00 - กวางบนฟ้า Fried Spicy Fish Cake (Appetizer)\n",
      "  $179.00 - ลักซี Minced Pork Mixed with Deep Fried Taro (Appetizer)\n",
      "\n",
      "----- Category C ($150.00 - $175.00) -----\n",
      "28 items:\n",
      "  $175.00 - Shrimp Fried with Curry Paste, Pineapple and Bitter Bean (Baht Main Course)\n",
      "  $175.00 - Hot Soup with pork ribs and young pepper (Main Course)\n",
      "  $170.00 - Whole Freshly Stuffed Chicken Saladc (Baht Main Course)\n",
      "  $170.00 - Whole Freshly Stuffed Chicken Salad (Baht Main Course)\n",
      "  $170.00 - Shrimp Paste Steamed in Traditional Style (Other Menu)\n",
      "  $170.00 - Deep Fried Chicken (Main Course)\n",
      "  $170.00 - Southern Curry with Trevally Fish without Coconut Milk (Main Course)\n",
      "  $170.00 - Steamed Fish Wrapped in Coconut Leave and Topping on Vegedatas (Main Course)\n",
      "  $169.00 - Shrimp Fried with Shrimp Paste, Pineapple and Bitter Bean (Baht Main Course)\n",
      "  $168.00 - Fried Rice with Shrimped Pork Belly and Grilled Fried Sea Bass (Main Course)\n",
      "  $160.00 - Fried Vegetables Dish เมนูผัดผัก (บาท Side Dish)\n",
      "  $160.00 - Grilled Chicken Thigh Basted with Soya Sauce โครงก้างไก่ (บาท Main Course)\n",
      "  $160.00 - Hot and Spicy Soup with Pineapple and Pork (THB Hot and Spicy Soup)\n",
      "  $160.00 - Fried Small Tossed with Flour, Tapioca, Starch Hokkaido Style (Main Course)\n",
      "  $160.00 - Fried Small Oyster with Tapioca Flour (baht Side Dish)\n",
      "  $159.00 - Stewed Eggplant in Curry Paste (Main Course)\n",
      "  $159.00 - กวางบนฟ้าลาน Fried Marinated Pork Cake Served with Sliced Ginger Dipping (Appetizer)\n",
      "  $159.00 - ปลาเง็ก Shredded Fried Mixed with Slice of Pork (Appetizer)\n",
      "  $150.00 - Stir-fried Kang Leaf with Eggs and Shrimp Pasted Shrimp ในเหล็ยงสมผัดใส่กุ้งเสียบ (บาท Main Course)\n",
      "  $150.00 - Fried Marinated Eggplant with Curry Paste (Baht Main Course)\n",
      "  $150.00 - Salted Fish from Ubon (Other Menu)\n",
      "  $150.00 - Fried Fish Cakes (Other Menu)\n",
      "  $150.00 - Fried Eggs with Salted Fish (Other Menu)\n",
      "  $150.00 - Fried Eggs, Onion, Shrimp, and Bitter Bean (Other Menu)\n",
      "  $150.00 - ปอเปี๊ยะสด Pineapple Salad (Appetizer)\n",
      "  $150.00 - Main Rice with Grilled Fried Mackerel (Gray) with Shrimp Paste Shrimp (Main Course)\n",
      "  $150.00 - Chicken Curry with Steamed Rice (Main Course)\n",
      "  $150.00 - Pork Chops with Fried Egg and Fried Sea Bass (Main Course)\n",
      "\n",
      "----- Category D ($18.00 - $149.00) -----\n",
      "13 items:\n",
      "  $149.00 - ทาบขาหมู Steamed Pork Belly Salad with Shrimp Paste (Appetizer)\n",
      "  $135.00 - Shrimp Pad Thai Phuket Style (baht Main Course)\n",
      "  $130.00 - Fried Egg Noodle Hokkaido Style (Main Course)\n",
      "  $130.00 - Massaman Curry (baht Main Course)\n",
      "  $129.00 - Khao Soi (baht Main Course)\n",
      "  $125.00 - Stir fried Shrimp Paste Served with Vegedatas (Chilli Paste Dishes)\n",
      "  $118.00 - Moo Grob (baht Main Course)\n",
      "  $99.00 - Taiwanese Style Banana Jelly, Red Bean and Red Syrup (Dessert)\n",
      "  $85.00 - Boiled flour cooked in Coconut Milk, Taro, Sweet Potato and Red Bean (Dessert)\n",
      "  $65.00 - Black sticky rice topping with coconut cream jelly (Dessert)\n",
      "  $50.00 - Drinking Water (Beverage)\n",
      "  $30.00 - Iced Tea (Beverage)\n",
      "  $18.00 - Soft Drink (Beverage)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "from anthropic import Anthropic\n",
    "from collections import defaultdict\n",
    "import logging # Import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Encode an image file to base64.\n",
    "\n",
    "    :param image_path: Path to the image file\n",
    "    :return: Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Image file not found: {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error encoding image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_from_image(api_key, image_paths, prompt_text):\n",
    "    \"\"\"\n",
    "    Use Claude to extract text from multiple images.\n",
    "\n",
    "    :param api_key: Your Anthropic API key\n",
    "    :param image_paths: List of paths to image files\n",
    "    :param prompt_text: Text prompt for Claude\n",
    "    :return: Extracted text from the images\n",
    "    \"\"\"\n",
    "    # Initialize the Anthropic client\n",
    "    client = Anthropic(api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        # Create content array\n",
    "        content = []\n",
    "\n",
    "        # Add each image to the content array\n",
    "        image_added = False\n",
    "        for image_path in image_paths:\n",
    "            # Determine media type based on file extension\n",
    "            media_type = \"image/jpeg\"  # Default\n",
    "            if image_path.lower().endswith(\".png\"):\n",
    "                media_type = \"image/png\"\n",
    "            elif image_path.lower().endswith(\".gif\"):\n",
    "                media_type = \"image/gif\"\n",
    "            elif image_path.lower().endswith(\".webp\"):\n",
    "                 media_type = \"image/webp\" # Add webp support\n",
    "\n",
    "\n",
    "            # Encode the image\n",
    "            logging.info(f\"Encoding image: {os.path.basename(image_path)}\")\n",
    "            base64_image = encode_image(image_path)\n",
    "\n",
    "            if base64_image:\n",
    "                # Add image to content array\n",
    "                content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": media_type,\n",
    "                        \"data\": base64_image\n",
    "                    }\n",
    "                })\n",
    "                image_added = True\n",
    "            else:\n",
    "                logging.warning(f\"Skipping image due to encoding error: {os.path.basename(image_path)}\")\n",
    "\n",
    "        if not image_added:\n",
    "            logging.error(\"No images could be successfully encoded and added.\")\n",
    "            return None\n",
    "\n",
    "        # Add text prompt at the end\n",
    "        content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt_text\n",
    "        })\n",
    "\n",
    "        # Send request to Claude\n",
    "        logging.info(\"Sending request to Claude API...\")\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\", # Using Haiku for speed/cost balance\n",
    "            # model=\"claude-3-opus-20240229\", # Opus might give better results but is slower/more expensive\n",
    "            max_tokens=4000, # Increased max_tokens slightly\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Return the extracted text\n",
    "        extracted_text = response.content[0].text\n",
    "        logging.info(f\"Received response from Claude. Content length: {len(extracted_text)} characters.\")\n",
    "        # Log first few lines of response for debugging\n",
    "        # logging.debug(\"Claude Response Head:\\n\" + \"\\n\".join(extracted_text.split('\\n')[:5]))\n",
    "        return extracted_text\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during Claude API call: {e}\", exc_info=True) # Log traceback\n",
    "        return None\n",
    "\n",
    "def parse_menu_items(extracted_text):\n",
    "    \"\"\"\n",
    "    Parse menu items, prices, and categories from extracted text.\n",
    "\n",
    "    :param extracted_text: Text extracted from the image by Claude\n",
    "    :return: Dictionary of menu items {name: {'price': float, 'category': str}}, plus confidence scores {name: float}\n",
    "    \"\"\"\n",
    "    menu_items = {}\n",
    "    confidence_scores = {}\n",
    "\n",
    "    # Basic check if extraction returned anything\n",
    "    if not extracted_text or not extracted_text.strip():\n",
    "        logging.warning(\"Received empty or null text from extraction.\")\n",
    "        return {}, {}\n",
    "\n",
    "    # Split the text into lines\n",
    "    lines = extracted_text.strip().split('\\n')\n",
    "    total_non_empty_lines = sum(1 for line in lines if line.strip())\n",
    "    successful_extractions = 0\n",
    "    unclear_items = 0\n",
    "    default_category_items = 0\n",
    "\n",
    "    logging.info(f\"Parsing {total_non_empty_lines} non-empty lines from Claude output.\")\n",
    "\n",
    "    # --- Refined Regex Patterns ---\n",
    "    # Price pattern: Handles various currency symbols (optional), commas, and decimals\n",
    "    # Makes currency symbol and spacing optional. Allows integer prices.\n",
    "    price_pattern = r'(?:[$€£¥]\\s*|\\b)(\\d+(?:,\\d{3})*(?:\\.\\d{1,2})?)\\b'\n",
    "    # Regex to find item name, price, and category (assumes format: NAME PRICE CATEGORY)\n",
    "    # It tries to be flexible with spacing and potential currency symbols.\n",
    "    # Group 1: Item Name (non-greedy)\n",
    "    # Group 2: Price (using price_pattern logic)\n",
    "    # Group 3: Category (rest of the line)\n",
    "    # This regex is complex and might need tuning based on Claude's actual output format.\n",
    "    # Let's try a simpler approach first: find price, then split.\n",
    "\n",
    "    for line_num, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        # Skip empty lines or potential headers/footers from Claude\n",
    "        if not line or line.startswith(\"Here are the items\") or line.startswith(\"---\"):\n",
    "            continue\n",
    "\n",
    "        line_confidence = 1.0  # Start with full confidence\n",
    "\n",
    "        # Check for uncertainty indicators in the text (global line check)\n",
    "        uncertainty_phrases = [\"unclear\", \"can't make out\", \"illegible\", \"not visible\", \"hard to read\", \"possibly\", \"maybe\", \"appears to be\"]\n",
    "        is_unclear = False\n",
    "        for phrase in uncertainty_phrases:\n",
    "            if phrase in line.lower():\n",
    "                line_confidence *= 0.6  # Reduce confidence if uncertainty is indicated globally\n",
    "                is_unclear = True\n",
    "                # break # Found one, no need to check others for this line\n",
    "\n",
    "        # 1. Find the price first (more reliable anchor)\n",
    "        price_match = re.search(price_pattern, line)\n",
    "\n",
    "        if price_match:\n",
    "            # Extract the price and convert to float\n",
    "            price_str = price_match.group(1).replace(',', '')\n",
    "            try:\n",
    "                price = float(price_str)\n",
    "            except ValueError:\n",
    "                logging.warning(f\"Line {line_num+1}: Could not convert price '{price_str}' to float. Skipping line: '{line}'\")\n",
    "                continue\n",
    "\n",
    "            # 2. Extract Item Name (everything before the price match)\n",
    "            item_name = line[:price_match.start()].strip()\n",
    "            # Clean up common trailing characters before price\n",
    "            item_name = re.sub(r'[.…\\-_*\\s]+$', '', item_name).strip()\n",
    "\n",
    "            # 3. Extract Category (everything after the price match)\n",
    "            category_name = line[price_match.end():].strip()\n",
    "            # Clean up common leading characters after price\n",
    "            category_name = re.sub(r'^[.…\\-_*\\s]+', '', category_name).strip()\n",
    "\n",
    "            # --- Data Cleaning and Validation ---\n",
    "            # Handle empty item name (likely parsing error or header)\n",
    "            if not item_name:\n",
    "                 logging.warning(f\"Line {line_num+1}: Extracted empty item name. Skipping line: '{line}'\")\n",
    "                 continue\n",
    "\n",
    "            # Handle empty or default category\n",
    "            if not category_name or category_name.lower() in [\"unclear\", \"unknown\", \"n/a\", \"none\", \"-\", \"--\"]:\n",
    "                category_name = \"Uncategorized\" # Standardize default\n",
    "                line_confidence *= 0.8 # Slightly reduce confidence if category was unclear/missing\n",
    "                default_category_items += 1\n",
    "\n",
    "            # Remove any \"(unclear)\" tags added by Claude from name/category\n",
    "            item_name = item_name.replace(\"(unclear)\", \"\").strip()\n",
    "            category_name = category_name.replace(\"(unclear)\", \"\").strip()\n",
    "\n",
    "            # If the global 'unclear' flag was set, mark item count\n",
    "            if is_unclear:\n",
    "                unclear_items += 1\n",
    "\n",
    "\n",
    "            # Check name/category quality (very short strings might be noise)\n",
    "            if len(item_name) < 3:\n",
    "                line_confidence *= 0.8\n",
    "            if len(category_name) < 3 and category_name != \"Uncategorized\": # Allow short defaults\n",
    "                 line_confidence *= 0.9 # Less penalty for short category\n",
    "\n",
    "            # Check price reasonableness\n",
    "            if price <= 0 or price > 1000: # Adjusted range slightly\n",
    "                line_confidence *= 0.7\n",
    "\n",
    "            # Store the item\n",
    "            successful_extractions += 1\n",
    "            item_key = item_name # Use name as the key\n",
    "\n",
    "            # Handle duplicate item names (append index if price/category differ)\n",
    "            if item_key in menu_items:\n",
    "                 existing_item = menu_items[item_key]\n",
    "                 # Only create variant if price OR category is different\n",
    "                 if existing_item['price'] != price or existing_item['category'] != category_name:\n",
    "                     count = 1\n",
    "                     new_key = f\"{item_name} ({count})\"\n",
    "                     while new_key in menu_items:\n",
    "                         count += 1\n",
    "                         new_key = f\"{item_name} ({count})\"\n",
    "                     item_key = new_key\n",
    "                     logging.info(f\"Duplicate item name '{item_name}' found with different price/category. Storing as '{item_key}'.\")\n",
    "                 else:\n",
    "                     # Exact duplicate, maybe increase confidence slightly? Or just skip. Let's skip.\n",
    "                     logging.info(f\"Exact duplicate item found: '{item_name}'. Skipping.\")\n",
    "                     successful_extractions -= 1 # Decrement success counter as we skipped it\n",
    "                     continue # Skip to next line\n",
    "\n",
    "            menu_items[item_key] = {'price': price, 'category': category_name}\n",
    "            confidence_scores[item_key] = max(0.0, min(1.0, line_confidence)) # Clamp confidence 0-1\n",
    "\n",
    "        else:\n",
    "            # Line did not contain a recognizable price pattern\n",
    "            logging.warning(f\"Line {line_num+1}: No valid price pattern found. Skipping line: '{line}'\")\n",
    "\n",
    "    # Calculate overall extraction quality metrics\n",
    "    extraction_rate = successful_extractions / total_non_empty_lines if total_non_empty_lines > 0 else 0\n",
    "    avg_confidence = sum(confidence_scores.values()) / len(confidence_scores) if confidence_scores else 0\n",
    "\n",
    "    # Log the extraction metrics\n",
    "    logging.info(f\"Parsing complete. Successfully extracted {successful_extractions} items.\")\n",
    "    logging.info(f\"Extraction rate: {extraction_rate:.1%} of non-empty lines.\")\n",
    "    logging.info(f\"Items marked unclear by Claude or parser: {unclear_items}\")\n",
    "    logging.info(f\"Items assigned default 'Uncategorized' category: {default_category_items}\")\n",
    "    logging.info(f\"Average confidence score for extracted items: {avg_confidence:.1%}\")\n",
    "\n",
    "    return menu_items, confidence_scores\n",
    "\n",
    "def categorize_menu_items(menu_items, num_categories=3):\n",
    "    \"\"\"\n",
    "    Categorize menu items based on their price into groups like A, B, C.\n",
    "\n",
    "    :param menu_items: Dictionary {name: {'price': float, 'category': str}}\n",
    "    :param num_categories: Number of price categories (A, B, C...)\n",
    "    :return: Dictionary {price_category: [{'name': str, 'price': float, 'category': str}, ...]}\n",
    "    \"\"\"\n",
    "    if not menu_items:\n",
    "        logging.warning(\"No menu items provided for price categorization.\")\n",
    "        return {}\n",
    "\n",
    "    # Prepare items list: [{'name': name, 'price': price, 'category': category}, ...]\n",
    "    items_list = [{'name': name, **data} for name, data in menu_items.items()]\n",
    "\n",
    "    # Sort items by price (descending)\n",
    "    sorted_items_list = sorted(items_list, key=lambda x: x['price'], reverse=True)\n",
    "\n",
    "    # Determine price ranges\n",
    "    prices = [item['price'] for item in sorted_items_list]\n",
    "    if not prices: # Should not happen if menu_items is not empty, but safety check\n",
    "        return {}\n",
    "\n",
    "    max_price = max(prices)\n",
    "    min_price = min(prices)\n",
    "    price_range = max_price - min_price\n",
    "\n",
    "    logging.info(f\"\\nPrice range for categorization: ${min_price:.2f} to ${max_price:.2f} (Spread: ${price_range:.2f})\")\n",
    "\n",
    "    # Create categories based on price ranges\n",
    "    # Result structure: {'A': [item_dict1, item_dict2], 'B': [...]}\n",
    "    categories = defaultdict(list)\n",
    "\n",
    "    # Handle edge cases: zero range or only one category requested\n",
    "    if num_categories <= 1 or price_range == 0:\n",
    "        logging.info(\"Assigning all items to Category A (single category requested or zero price range).\")\n",
    "        categories['A'].extend(sorted_items_list)\n",
    "        return dict(categories) # Convert back to dict from defaultdict\n",
    "\n",
    "    # --- Adaptive Categorization Logic (from original code) ---\n",
    "    # Decide whether to use equal price range division or percentile-based division\n",
    "    large_range_threshold = 3.0 # Use adaptive if range > 3x min price\n",
    "    use_adaptive = price_range > min_price * large_range_threshold and min_price > 0\n",
    "\n",
    "    if use_adaptive:\n",
    "        logging.info(f\"Large price range detected (range/min > {large_range_threshold:.1f}) - using adaptive (percentile-based) categorization.\")\n",
    "\n",
    "        num_items = len(sorted_items_list)\n",
    "        category_boundaries = [] # List of lower bounds for categories B, C, D...\n",
    "\n",
    "        # Calculate boundary prices based on item count percentiles\n",
    "        for i in range(1, num_categories):\n",
    "            idx = int((i * num_items) / num_categories)\n",
    "            # Use the price of the item at the boundary index as the threshold\n",
    "            # Ensure index is valid\n",
    "            if 0 <= idx < num_items:\n",
    "                 # The boundary is the price *below which* items fall into the next category\n",
    "                 # So, category A is >= boundary[0], B is < boundary[0] and >= boundary[1], etc.\n",
    "                 boundary_price = sorted_items_list[idx]['price']\n",
    "                 # Add a small epsilon if needed to handle exact matches at boundaries consistently\n",
    "                 # Let's adjust logic: boundary price IS the lower limit for the higher category\n",
    "                 category_boundaries.append(boundary_price)\n",
    "            else:\n",
    "                 # Should not happen with valid indices, but handle gracefully\n",
    "                 logging.warning(f\"Could not determine boundary price for category {chr(65 + i)}\")\n",
    "                 # Use the previous boundary or min price as fallback\n",
    "                 category_boundaries.append(category_boundaries[-1] if category_boundaries else min_price)\n",
    "\n",
    "        # Ensure boundaries are unique and sorted descending\n",
    "        category_boundaries = sorted(list(set(category_boundaries)), reverse=True)\n",
    "\n",
    "        # Add the minimum price as the effective floor for the last category\n",
    "        category_boundaries.append(min_price - 0.01) # Ensure min_price items are included\n",
    "\n",
    "        boundary_strs = [f\">${b:.2f}\" for b in category_boundaries[:-1]] # Don't print the floor boundary\n",
    "        logging.info(f\"Adaptive category price boundaries (Min price for Cat A, B, C...): {boundary_strs}\")\n",
    "\n",
    "        # Assign items to categories based on these boundaries\n",
    "        for item_dict in sorted_items_list:\n",
    "            item_price = item_dict['price']\n",
    "            assigned = False\n",
    "            # Find the first boundary the price is >= to\n",
    "            for i, boundary in enumerate(category_boundaries[:-1]): # Iterate through A, B, C... boundaries\n",
    "                 if item_price >= boundary:\n",
    "                     category_letter = chr(65 + i)\n",
    "                     categories[category_letter].append(item_dict)\n",
    "                     assigned = True\n",
    "                     break\n",
    "            # If not assigned (should only happen for min_price items falling below last explicit boundary)\n",
    "            if not assigned:\n",
    "                 # Assign to the last category\n",
    "                 category_letter = chr(65 + num_categories - 1)\n",
    "                 categories[category_letter].append(item_dict)\n",
    "\n",
    "    else:\n",
    "        # --- Standard Equal Price Range Division ---\n",
    "        logging.info(\"Using standard categorization (equal price range division).\")\n",
    "        # Avoid division by zero if num_categories is 0 or less (handled earlier, but safety)\n",
    "        if num_categories <= 0: num_categories = 1\n",
    "        category_range_size = price_range / num_categories\n",
    "\n",
    "        # Print calculated category ranges\n",
    "        logging.info(f\"Calculated category range size: ${category_range_size:.2f}\")\n",
    "        for i in range(num_categories):\n",
    "             cat_letter = chr(65 + i)\n",
    "             cat_max = max_price - (i * category_range_size)\n",
    "             cat_min = max_price - ((i + 1) * category_range_size)\n",
    "             # Ensure the last category includes the minimum price exactly\n",
    "             if i == num_categories - 1: cat_min = min_price\n",
    "             logging.info(f\"  Target range for Category {cat_letter}: ~${cat_min:.2f} - ${cat_max:.2f}\")\n",
    "\n",
    "\n",
    "        for item_dict in sorted_items_list:\n",
    "            item_price = item_dict['price']\n",
    "            # Determine category index based on price position within the total range\n",
    "            # Handle max_price edge case: should be in Category A (index 0)\n",
    "            if item_price == max_price:\n",
    "                category_index = 0\n",
    "            # Avoid division by zero if category_range_size is 0 (handled earlier, but safety)\n",
    "            elif category_range_size > 0:\n",
    "                 # Calculate how many 'ranges' down from the max price this item is\n",
    "                 category_index = int((max_price - item_price) / category_range_size)\n",
    "                 # Clamp index to valid range [0, num_categories - 1]\n",
    "                 category_index = max(0, min(num_categories - 1, category_index))\n",
    "            else: # category_range_size is 0 (all prices same) -> should be handled by initial check\n",
    "                 category_index = 0\n",
    "\n",
    "            category_letter = chr(65 + category_index)\n",
    "            categories[category_letter].append(item_dict)\n",
    "\n",
    "    # Log the distribution of items across final categories\n",
    "    logging.info(\"\\n--- Final Item Distribution by Price Category ---\")\n",
    "    for category_letter, items in sorted(categories.items()):\n",
    "        category_min_price = min(item['price'] for item in items) if items else 0\n",
    "        category_max_price = max(item['price'] for item in items) if items else 0\n",
    "        logging.info(f\"Category {category_letter}: {len(items)} items. Actual price range: ${category_min_price:.2f} - ${category_max_price:.2f}\")\n",
    "\n",
    "    return dict(categories) # Convert back to regular dict\n",
    "\n",
    "\n",
    "def process_menu_images(api_key, image_folder, num_price_categories=3):\n",
    "    \"\"\"\n",
    "    Process all menu images in a folder, extract items (name, price, category),\n",
    "    and categorize them by price tiers (A, B, C...).\n",
    "\n",
    "    :param api_key: Your Anthropic API key\n",
    "    :param image_folder: Path to folder containing menu images\n",
    "    :param num_price_categories: Number of price categories (A, B, C...)\n",
    "    :return: Price-categorized menu items dict, and overall confidence scores dict\n",
    "    \"\"\"\n",
    "    # List all image files in the folder\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp'] # Added webp\n",
    "    image_paths = []\n",
    "\n",
    "    if not os.path.isdir(image_folder):\n",
    "        logging.error(f\"Image folder not found or is not a directory: {image_folder}\")\n",
    "        return {}, {}\n",
    "\n",
    "    for file in os.listdir(image_folder):\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            image_paths.append(os.path.join(image_folder, file))\n",
    "\n",
    "    if not image_paths:\n",
    "        logging.error(f\"No supported image files ({', '.join(image_extensions)}) found in {image_folder}\")\n",
    "        return {}, {}\n",
    "\n",
    "    logging.info(f\"Found {len(image_paths)} images to process in folder: {image_folder}\")\n",
    "\n",
    "    # Store all items extracted across all images before final categorization\n",
    "    # Using the structure: {name: {'price': float, 'category': str}}\n",
    "    all_menu_items_combined = {}\n",
    "    all_confidence_scores_combined = {}\n",
    "    image_extraction_counts = []\n",
    "\n",
    "    # --- Updated Prompt for Claude ---\n",
    "    prompt_text = f\"\"\"\n",
    "    Please extract all menu items from the provided image(s).\n",
    "    For each distinct menu item found, provide the following information on a single line:\n",
    "    1. The complete Item Name.\n",
    "    2. The exact Price (including currency symbol like $ or € if visible, otherwise just the number).\n",
    "    3. The item's Category (e.g., Appetizer, Main Course, Dessert, Beverage, Side Dish).\n",
    "\n",
    "    Format each item STRICTLY as:\n",
    "    Item Name $Price Category\n",
    "\n",
    "    Examples:\n",
    "    Classic Caesar Salad $12.99 Appetizer\n",
    "    Grilled Salmon Fillet $24.50 Main Course\n",
    "    New York Cheesecake $8.00 Dessert\n",
    "    Iced Tea $3.50 Beverage\n",
    "    French Fries $5.00 Side Dish\n",
    "\n",
    "    IMPORTANT INSTRUCTIONS:\n",
    "    - List EVERY visible menu item, even if unsure about details.\n",
    "    - If you cannot clearly determine the Item Name, Price, or Category, use the placeholder \"(unclear)\" for that specific part. For example: \"House Special (unclear) $16.99 Main Course\" or \"Spicy Tuna Roll $15.00 (unclear)\". If the category is totally unknown, use \"Uncategorized\".\n",
    "    - Ensure the price is extracted accurately.\n",
    "    - Do NOT add any introductory text, explanations, summaries, or formatting like bullet points or markdown. Only output the list of items in the specified format, one item per line.\n",
    "    - If an item seems to span multiple lines in the menu, combine it into a single logical item name if possible.\n",
    "    - Pay attention to sections or headers in the menu image to help determine the category.\n",
    "    \"\"\"\n",
    "\n",
    "    # Process images (can be done one-by-one or batched if API/model supports it well)\n",
    "    # Let's stick to one-by-one for simplicity and robustness against single image failures.\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        logging.info(f\"\\n--- Processing image {idx+1}/{len(image_paths)}: {os.path.basename(image_path)} ---\")\n",
    "\n",
    "        extracted_text = extract_text_from_image(api_key, [image_path], prompt_text)\n",
    "\n",
    "        if extracted_text:\n",
    "            logging.info(f\"Text extraction successful for {os.path.basename(image_path)}. Parsing content...\")\n",
    "\n",
    "            # Parse menu items (name, price, category) from this image's text\n",
    "            menu_items_single, confidence_scores_single = parse_menu_items(extracted_text)\n",
    "            item_count_single = len(menu_items_single)\n",
    "            logging.info(f\"Parsed {item_count_single} items from {os.path.basename(image_path)}.\")\n",
    "            image_extraction_counts.append((os.path.basename(image_path), item_count_single))\n",
    "\n",
    "            # Merge items from this image into the combined dictionary\n",
    "            for item_name, item_data in menu_items_single.items():\n",
    "                confidence = confidence_scores_single.get(item_name, 0.5) # Default confidence if missing\n",
    "\n",
    "                # Check if item already exists in combined list\n",
    "                if item_name in all_menu_items_combined:\n",
    "                    existing_data = all_menu_items_combined[item_name]\n",
    "                    # If price or category differs, create a variant\n",
    "                    if existing_data['price'] != item_data['price'] or existing_data['category'] != item_data['category']:\n",
    "                        variant_count = 1\n",
    "                        variant_name = f\"{item_name} (Img {idx+1})\" # Add image source to variant name\n",
    "                        while variant_name in all_menu_items_combined:\n",
    "                             variant_count += 1\n",
    "                             variant_name = f\"{item_name} (Img {idx+1} Var {variant_count})\"\n",
    "\n",
    "                        logging.warning(f\"Item '{item_name}' from {os.path.basename(image_path)} differs from previous entry. Storing as '{variant_name}'. \"\n",
    "                                        f\"Old: P={existing_data['price']}, C='{existing_data['category']}'. New: P={item_data['price']}, C='{item_data['category']}'.\")\n",
    "                        all_menu_items_combined[variant_name] = item_data\n",
    "                        all_confidence_scores_combined[variant_name] = confidence\n",
    "                    else:\n",
    "                         # Exact same item found again, potentially update confidence if higher?\n",
    "                         # For now, let's keep the first encountered confidence.\n",
    "                         logging.info(f\"Item '{item_name}' is an exact duplicate from another image. Skipping.\")\n",
    "                else:\n",
    "                    # New item, add it\n",
    "                    all_menu_items_combined[item_name] = item_data\n",
    "                    all_confidence_scores_combined[item_name] = confidence\n",
    "\n",
    "            logging.info(f\"Combined total unique items so far: {len(all_menu_items_combined)}\")\n",
    "        else:\n",
    "            logging.error(f\"Failed to extract text from {os.path.basename(image_path)}. Skipping this image.\")\n",
    "            image_extraction_counts.append((os.path.basename(image_path), 0)) # Record failure\n",
    "\n",
    "    # --- Post-Processing and Categorization ---\n",
    "    logging.info(f\"\\n===== Image Processing Summary =====\")\n",
    "    total_items_extracted = sum(count for _, count in image_extraction_counts)\n",
    "    logging.info(f\"Total items parsed across all images (before deduplication/variants): {total_items_extracted}\")\n",
    "    logging.info(f\"Final unique items/variants stored: {len(all_menu_items_combined)}\")\n",
    "\n",
    "    # Print extraction performance by image\n",
    "    logging.info(\"\\nItems Parsed Per Image:\")\n",
    "    for image_name, item_count in image_extraction_counts:\n",
    "        logging.info(f\"  {image_name}: {item_count} items\")\n",
    "\n",
    "    # Calculate overall average confidence score\n",
    "    if all_confidence_scores_combined:\n",
    "        avg_confidence = sum(all_confidence_scores_combined.values()) / len(all_confidence_scores_combined)\n",
    "        logging.info(f\"Overall average extraction confidence: {avg_confidence:.1%}\")\n",
    "    else:\n",
    "         logging.info(\"No confidence scores available.\")\n",
    "\n",
    "\n",
    "    if not all_menu_items_combined:\n",
    "        logging.error(\"No menu items were successfully extracted from any images.\")\n",
    "        return {}, {}\n",
    "\n",
    "    # --- Dynamic Adjustment of Price Categories ---\n",
    "    # Adjust num_categories based on item count for better distribution\n",
    "    min_items_per_category = 3 # Aim for at least 3 items per category if possible\n",
    "    max_possible_categories = len(all_menu_items_combined) // min_items_per_category\n",
    "    adjusted_categories = max(1, min(num_price_categories, max_possible_categories))\n",
    "\n",
    "    if adjusted_categories != num_price_categories:\n",
    "        logging.warning(f\"Adjusting number of price categories from {num_price_categories} to {adjusted_categories} \"\n",
    "                      f\"based on item count ({len(all_menu_items_combined)}) and target minimum items per category ({min_items_per_category}).\")\n",
    "        num_price_categories = adjusted_categories\n",
    "    else:\n",
    "         logging.info(f\"Using requested number of price categories: {num_price_categories}\")\n",
    "\n",
    "    # Categorize the combined menu items by price tiers (A, B, C...)\n",
    "    logging.info(\"\\n--- Categorizing All Extracted Items by Price ---\")\n",
    "    final_price_categories = categorize_menu_items(all_menu_items_combined, num_price_categories)\n",
    "\n",
    "    return final_price_categories, all_confidence_scores_combined\n",
    "\n",
    "def main():\n",
    "    # --- Configuration ---\n",
    "    # IMPORTANT: Replace with your actual Anthropic API key\n",
    "    # Consider using environment variables for API keys in production\n",
    "    API_KEY = os.environ.get('ANTHROPIC_API_KEY') # Looks for env var first\n",
    "\n",
    "    if not API_KEY:\n",
    "        logging.error(\"CRITICAL: Anthropic API key not found. Set the ANTHROPIC_API_KEY environment variable or replace 'YOUR_API_KEY_HERE' in the script.\")\n",
    "        return\n",
    "\n",
    "    # Path to your folder containing menu images\n",
    "    IMAGE_FOLDER = './test_menus/test_menu2' # Make sure this folder exists and contains images\n",
    "\n",
    "    # Target number of *price* categories (e.g., A, B, C, D for 4 categories)\n",
    "    NUM_PRICE_CATEGORIES = 4\n",
    "\n",
    "    # Output file name\n",
    "    OUTPUT_FILENAME = \"categorized_menu_items.txt\"\n",
    "    # --- End Configuration ---\n",
    "\n",
    "\n",
    "    logging.info(\"===== MENU ITEM EXTRACTION AND PRICE CATEGORIZATION =====\")\n",
    "    logging.info(f\"Processing menu images from folder: {os.path.abspath(IMAGE_FOLDER)}\")\n",
    "    logging.info(f\"Target number of price categories: {NUM_PRICE_CATEGORIES}\")\n",
    "\n",
    "    # Create image folder if it doesn't exist (useful for first run)\n",
    "    if not os.path.exists(IMAGE_FOLDER):\n",
    "        try:\n",
    "            os.makedirs(IMAGE_FOLDER)\n",
    "            logging.info(f\"Created image folder: {IMAGE_FOLDER}\")\n",
    "            logging.warning(\"Image folder was created, but it's currently empty. Please add menu images to it.\")\n",
    "            return # Stop execution if folder was just created empty\n",
    "        except OSError as e:\n",
    "            logging.error(f\"Failed to create image folder {IMAGE_FOLDER}: {e}\")\n",
    "            return\n",
    "\n",
    "\n",
    "    # Process menu images\n",
    "    price_categories, confidence_scores = process_menu_images(API_KEY, IMAGE_FOLDER, NUM_PRICE_CATEGORIES)\n",
    "\n",
    "    if price_categories:\n",
    "        # --- Output Results ---\n",
    "        logging.info(\"\\n========== FINAL MENU ITEMS BY PRICE CATEGORY ==========\")\n",
    "        # Print to console\n",
    "        for category_letter, items in sorted(price_categories.items()):\n",
    "            if items:\n",
    "                # Sort items within the category by price (desc) for printing\n",
    "                items_sorted = sorted(items, key=lambda x: x['price'], reverse=True)\n",
    "                category_min_price = items_sorted[-1]['price']\n",
    "                category_max_price = items_sorted[0]['price']\n",
    "                print(f\"\\n----- Category {category_letter} (${category_min_price:.2f} - ${category_max_price:.2f}) -----\")\n",
    "                print(f\"{len(items)} items:\")\n",
    "\n",
    "                for item_dict in items_sorted:\n",
    "                    # Display Name, Price, and the SEMANTIC Category extracted by Claude\n",
    "                    print(f\"  ${item_dict['price']:.2f} - {item_dict['name']} ({item_dict['category']})\") # Include semantic category in print\n",
    "\n",
    "        # Save categorized items to a file\n",
    "        try:\n",
    "            output_path = os.path.abspath(OUTPUT_FILENAME)\n",
    "            logging.info(f\"\\nSaving results to: {output_path}\")\n",
    "            with open(output_path, \"w\", encoding='utf-8') as f:\n",
    "                f.write(\"===== MENU ITEMS BY PRICE CATEGORY (Generated by Script) =====\\n\")\n",
    "                f.write(f\"Processed images from: {os.path.abspath(IMAGE_FOLDER)}\\n\")\n",
    "                # Optionally add confidence score info here if desired\n",
    "                # avg_conf = (sum(confidence_scores.values()) / len(confidence_scores)) * 100 if confidence_scores else 0\n",
    "                # f.write(f\"Average Extraction Confidence: {avg_conf:.1f}%\\n\")\n",
    "\n",
    "                for category_letter, items in sorted(price_categories.items()):\n",
    "                    if items:\n",
    "                        # Sort items within the category by price (desc) for writing\n",
    "                        items_sorted = sorted(items, key=lambda x: x['price'], reverse=True)\n",
    "                        category_min_price = items_sorted[-1]['price']\n",
    "                        category_max_price = items_sorted[0]['price']\n",
    "                        f.write(f\"\\n----- Category {category_letter} (${category_min_price:.2f} - ${category_max_price:.2f}) -----\\n\")\n",
    "\n",
    "                        for item_dict in items_sorted:\n",
    "                            # Write in the format expected by the *other* script,\n",
    "                            # BUT let's include the semantic category in parentheses.\n",
    "                            # The other script's parser might need adjustment if it can't handle this.\n",
    "                            f.write(f\"  ${item_dict['price']:.2f} - {item_dict['name']} ({item_dict['category']})\\n\")\n",
    "            logging.info(f\"Results successfully saved to {OUTPUT_FILENAME}\")\n",
    "        except IOError as e:\n",
    "            logging.error(f\"Error saving results to file '{OUTPUT_FILENAME}': {e}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An unexpected error occurred during file writing: {e}\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(\"Processing finished, but no menu items were found or categorized.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bundle Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 22:34:18,304 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-25 22:34:18,305 - INFO - AFC remote call 1 is done.\n",
      "2025-04-25 22:34:43,818 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-exp-03-25:streamGenerateContent?alt=sse \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"bundle_name\": \"Solo Feast\",\n",
      "    \"suggested_bundle_price\": 593.00,\n",
      "    \"number_of_diners\": 1,\n",
      "    \"category_portions\": {\n",
      "      \"Category A\": 1,\n",
      "      \"Category B\": 1,\n",
      "      \"Category C\": 1,\n",
      "      \"Category D\": 1\n",
      "    },\n",
      "    \"original_bundle_price\": 674.00,\n",
      "    \"discount_percentage\": 12.02,\n",
      "    \"price_per_diner\": 593.00\n",
      "  },\n",
      "  {\n",
      "    \"bundle_name\": \"Couple's Delight\",\n",
      "    \"suggested_bundle_price\": 973.00,\n",
      "    \"number_of_diners\": 2,\n",
      "    \"category_portions\": {\n",
      "      \"Category A\": 1,\n",
      "      \"Category B\": 1,\n",
      "      \"Category C\": 1,\n",
      "      \"Category D\": 3\n",
      "    },\n",
      "    \"original_bundle_price\": 1145.00,\n",
      "    \"discount_percentage\": 15.02,\n",
      "    \"price_per_diner\": 486.50\n",
      "  },\n",
      "  {\n",
      "    \"bundle_name\": \"Phuket Flavors Sampler\",\n",
      "    \"suggested_bundle_price\": 1440.00,\n",
      "    \"number_of_diners\": 4,\n",
      "    \"category_portions\": {\n",
      "      \"Category A\": 2,\n",
      "      \"Category B\": 2,\n",
      "      \"Category C\": 2,\n",
      "      \"Category D\": 6\n",
      "    },\n",
      "    \"original_bundle_price\": 1756.00,\n",
      "    \"discount_percentage\": 18.00,\n",
      "    \"price_per_diner\": 360.00\n",
      "  },\n",
      "  {\n",
      "    \"bundle_name\": \"Southern Grand Feast\",\n",
      "    \"suggested_bundle_price\": 2003.00,\n",
      "    \"number_of_diners\": 6,\n",
      "    \"category_portions\": {\n",
      "      \"Category A\": 2,\n",
      "      \"Category B\": 2,\n",
      "      \"Category C\": 2,\n",
      "      \"Category D\": 10\n",
      "    },\n",
      "    \"original_bundle_price\": 2504.00,\n",
      "    \"discount_percentage\": 20.01,\n",
      "    \"price_per_diner\": 333.83\n",
      "  }\n",
      "]\n",
      "\n",
      "Parsing response as JSON...\n",
      "Saved 4 unique menu bundles to menu_bundles.json\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def generate():\n",
    "    try:\n",
    "        client = genai.Client(\n",
    "            api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Gemini client: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if categorized_menu_items.txt exists\n",
    "    if not os.path.exists(\"./categorized_menu_items.txt\"):\n",
    "        print(\"Error: categorized_menu_items.txt file not found\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Read the file content\n",
    "        with open(\"./categorized_menu_items.txt\", \"r\") as file:\n",
    "            menu_content = file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading menu file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create prompt with the file content\n",
    "    prompt = f\"\"\"\n",
    "    Based on these categorised menu data:\n",
    "    \n",
    "    {menu_content}\n",
    "    \n",
    "    Please create 4 UNIQUE menu bundles for a varying number of diners (1-6 diners). Each bundle must include some items from each available menu category (A, B, C, and D if present).\n",
    "    \n",
    "    For each menu bundle, include:\n",
    "    1. The number of menu items from each category\n",
    "    2. The number of diners the bundle is designed for\n",
    "    3. The price per diner\n",
    "    4. A suggested discounted bundle price\n",
    "\n",
    "    Please follow this exact structure for each menu bundle:\n",
    "    Suggested bundle price:\n",
    "    Number of diners:\n",
    "    category_portionss:\n",
    "        Category A: [number of items]\n",
    "        Category B: [number of items]\n",
    "        Category C: [number of items]\n",
    "        Category D: [number of items]\n",
    "    Original bundle price:\n",
    "    Discount percentage:\n",
    "    Price per diner:\n",
    "    \n",
    "    Note: Include all four categories (A through D) in your response, even if some categories might have 0 items in certain bundles.\n",
    "    \"\"\"\n",
    "\n",
    "    model = \"gemini-2.5-pro-exp-03-25\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        system_instruction=[\n",
    "            types.Part.from_text(text=\"\"\"You are a menu bundle generator, and your task is to create 4 UNIQUE menu bundles based on a given input of menu categories. Each bundle should be distinctly different from the others. For each bundle:\n",
    "            \n",
    "1. Include items from all available categories (A, B, C, and D)\n",
    "2. Specify exactly how many portions from each category are included\n",
    "3. Calculate the original price based on the actual menu prices\n",
    "4. Apply a reasonable discount (10-20%)\n",
    "5. Calculate the per-person price\n",
    "            \n",
    "Always include all four categories (A through D) in your response structure, even if some categories have 0 items or don't exist in the input data.\"\"\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Collect the entire response\n",
    "    complete_response = \"\"\n",
    "    \n",
    "    try:\n",
    "        # Get the response generator\n",
    "        response_stream = client.models.generate_content_stream(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=generate_content_config,\n",
    "        )\n",
    "        \n",
    "        # Check if response is None\n",
    "        if response_stream is None:\n",
    "            print(\"Warning: API returned None for response stream\")\n",
    "            # Try non-streaming version as fallback\n",
    "            try:\n",
    "                print(\"Attempting to use non-streaming API as fallback...\")\n",
    "                response = client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=contents,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "                \n",
    "                if response and hasattr(response, 'text'):\n",
    "                    complete_response = response.text\n",
    "                elif response and hasattr(response, 'parts'):\n",
    "                    for part in response.parts:\n",
    "                        if hasattr(part, 'text') and part.text is not None:\n",
    "                            complete_response += part.text\n",
    "                else:\n",
    "                    print(\"Warning: Fallback response format is unexpected\")\n",
    "            except Exception as fallback_error:\n",
    "                print(f\"Fallback request also failed: {fallback_error}\")\n",
    "        else:\n",
    "            # Iterate through streaming response if it's not None\n",
    "            for chunk in response_stream:\n",
    "                # Handle the case where chunk.text might be None\n",
    "                # Get the text from different potential structures\n",
    "                chunk_text = \"\"\n",
    "                \n",
    "                # Try direct text property\n",
    "                if hasattr(chunk, 'text') and chunk.text is not None:\n",
    "                    chunk_text = chunk.text\n",
    "                # Try looking in parts\n",
    "                elif hasattr(chunk, 'parts') and chunk.parts:\n",
    "                    # Combine text from all parts\n",
    "                    for part in chunk.parts:\n",
    "                        if hasattr(part, 'text') and part.text is not None:\n",
    "                            chunk_text += part.text\n",
    "                # Try candidates structure\n",
    "                elif hasattr(chunk, 'candidates') and chunk.candidates:\n",
    "                    for candidate in chunk.candidates:\n",
    "                        if hasattr(candidate, 'content'):\n",
    "                            content = candidate.content\n",
    "                            if hasattr(content, 'parts'):\n",
    "                                for part in content.parts:\n",
    "                                    if hasattr(part, 'text') and part.text is not None:\n",
    "                                        chunk_text += part.text\n",
    "                \n",
    "                # Add to the complete response\n",
    "                complete_response += chunk_text\n",
    "                \n",
    "                # Print to console\n",
    "                if chunk_text:\n",
    "                    print(chunk_text, end=\"\")\n",
    "                else:\n",
    "                    print(\".\", end=\"\")  # Print a dot to indicate progress for empty chunks\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nError during generation: {e}\")\n",
    "        \n",
    "        # Last-ditch effort - try non-streaming API if streaming failed\n",
    "        if not complete_response:\n",
    "            try:\n",
    "                print(\"Attempting to use non-streaming API as final fallback...\")\n",
    "                response = client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=contents,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "                \n",
    "                if hasattr(response, 'text') and response.text:\n",
    "                    complete_response = response.text\n",
    "                    print(f\"Received {len(complete_response)} characters from fallback request\")\n",
    "            except Exception as fallback_error:\n",
    "                print(f\"Fallback request also failed: {fallback_error}\")\n",
    "    \n",
    "    # Save the raw response for debugging\n",
    "    try:\n",
    "        with open(\"menu_bundles_raw.txt\", \"w\") as f:\n",
    "            f.write(complete_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving raw response: {e}\")\n",
    "    \n",
    "    # Parse and save as JSON\n",
    "    try:\n",
    "        print(\"\\n\\nParsing response as JSON...\")\n",
    "        \n",
    "        # Check if the response is empty\n",
    "        if not complete_response.strip():\n",
    "            raise ValueError(\"Empty response received from API\")\n",
    "            \n",
    "        # Try direct JSON parsing first\n",
    "        all_valid_jsons = []\n",
    "        unique_bundles = set()  # Use a set to track unique bundles\n",
    "        \n",
    "        try:\n",
    "            # First, try parsing the entire response as a single JSON object\n",
    "            json_data = json.loads(complete_response)\n",
    "            if isinstance(json_data, list):\n",
    "                # If it's a list, use it directly\n",
    "                all_valid_jsons = json_data[:4]  # Limit to 4 bundles\n",
    "            else:\n",
    "                # If it's an object, check if it has a 'bundles' property\n",
    "                if \"bundles\" in json_data and isinstance(json_data[\"bundles\"], list):\n",
    "                    json_data[\"bundles\"] = json_data[\"bundles\"][:4]  # Limit to 4 bundles\n",
    "                all_valid_jsons = [json_data]\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Direct JSON parsing failed, trying extraction methods...\")\n",
    "            \n",
    "            # Look for JSON objects pattern\n",
    "            json_pattern = r'(\\{(?:[^{}]|(?:\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}))*\\})'\n",
    "            json_matches = re.findall(json_pattern, complete_response)\n",
    "            \n",
    "            if json_matches:\n",
    "                # Try each potential JSON match\n",
    "                potential_jsons = sorted(json_matches, key=len, reverse=True)\n",
    "                \n",
    "                for potential_json in potential_jsons:\n",
    "                    try:\n",
    "                        json_data = json.loads(potential_json)\n",
    "                        # Convert to string for comparison to check uniqueness\n",
    "                        json_str = json.dumps(json_data, sort_keys=True)\n",
    "                        if json_str not in unique_bundles:\n",
    "                            unique_bundles.add(json_str)\n",
    "                            all_valid_jsons.append(json_data)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "            \n",
    "            # Also try code blocks\n",
    "            code_block_matches = re.findall(r'```(?:json)?(.*?)```', complete_response, re.DOTALL)\n",
    "            for code_block in code_block_matches:\n",
    "                try:\n",
    "                    json_data = json.loads(code_block.strip())\n",
    "                    # Check uniqueness again\n",
    "                    json_str = json.dumps(json_data, sort_keys=True)\n",
    "                    if json_str not in unique_bundles:\n",
    "                        unique_bundles.add(json_str)\n",
    "                        all_valid_jsons.append(json_data)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        # Ensure we have only 4 bundles maximum\n",
    "        if len(all_valid_jsons) > 4:\n",
    "            all_valid_jsons = all_valid_jsons[:4]\n",
    "        \n",
    "        # Save all valid JSONs to a single file\n",
    "        if all_valid_jsons:\n",
    "            with open(\"menu_bundles.json\", \"w\") as json_file:\n",
    "                json.dump(all_valid_jsons, json_file, indent=4)\n",
    "            print(f\"Saved {len(all_valid_jsons)} unique menu bundles to menu_bundles.json\")\n",
    "        else:\n",
    "            print(\"No valid JSONs found in the response\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to parse response as JSON: {e}\")\n",
    "        print(\"Please check menu_bundles_raw.txt to see the actual response.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Excel Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 22:34:53,056 - INFO - Attempting to read bundles from: /Users/Cwkf_89/Documents/GitHub/hungryhub_automation/menu_bundles.json\n",
      "2025-04-25 22:34:53,057 - INFO - Successfully loaded 4 bundles from ./menu_bundles.json\n",
      "2025-04-25 22:34:53,057 - INFO - Attempting to read menu items from: /Users/Cwkf_89/Documents/GitHub/hungryhub_automation/categorized_menu_items.txt\n",
      "2025-04-25 22:34:53,058 - INFO - Line 4: Found Price Band Header 'Category A'\n",
      "2025-04-25 22:34:53,059 - INFO - Line 28: Found Price Band Header 'Category B'\n",
      "2025-04-25 22:34:53,059 - INFO - Line 54: Found Price Band Header 'Category C'\n",
      "2025-04-25 22:34:53,060 - INFO - Line 84: Found Price Band Header 'Category D'\n",
      "2025-04-25 22:34:53,060 - INFO - Successfully parsed 87 menu items from ./categorized_menu_items.txt\n",
      "2025-04-25 22:34:53,061 - INFO - --- Parsed Menu Items Summary (by Price Band) ---\n",
      "2025-04-25 22:34:53,061 - INFO -   Category A: 22 items\n",
      "2025-04-25 22:34:53,061 - INFO -   Category B: 24 items\n",
      "2025-04-25 22:34:53,061 - INFO -   Category C: 28 items\n",
      "2025-04-25 22:34:53,062 - INFO -   Category D: 13 items\n",
      "2025-04-25 22:34:53,062 - INFO - -------------------------------------------------\n",
      "2025-04-25 22:34:53,065 - INFO - Processing Category A on row 8\n",
      "2025-04-25 22:34:53,065 - INFO -   Processing bundle: Solo Feast\n",
      "2025-04-25 22:34:53,066 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,066 - INFO -     Set cell B8 to 1\n",
      "2025-04-25 22:34:53,066 - INFO -   Processing bundle: Couple's Delight\n",
      "2025-04-25 22:34:53,067 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,067 - INFO -     Set cell D8 to 1\n",
      "2025-04-25 22:34:53,067 - INFO -   Processing bundle: Phuket Flavors Sampler\n",
      "2025-04-25 22:34:53,067 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,068 - INFO -     Set cell F8 to 2\n",
      "2025-04-25 22:34:53,068 - INFO -   Processing bundle: Southern Grand Feast\n",
      "2025-04-25 22:34:53,069 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,069 - INFO -     Set cell H8 to 2\n",
      "2025-04-25 22:34:53,069 - INFO - Processing Category B on row 9\n",
      "2025-04-25 22:34:53,070 - INFO -   Processing bundle: Solo Feast\n",
      "2025-04-25 22:34:53,070 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,071 - INFO -     Set cell B9 to 1\n",
      "2025-04-25 22:34:53,071 - INFO -   Processing bundle: Couple's Delight\n",
      "2025-04-25 22:34:53,071 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,072 - INFO -     Set cell D9 to 1\n",
      "2025-04-25 22:34:53,072 - INFO -   Processing bundle: Phuket Flavors Sampler\n",
      "2025-04-25 22:34:53,072 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,073 - INFO -     Set cell F9 to 2\n",
      "2025-04-25 22:34:53,073 - INFO -   Processing bundle: Southern Grand Feast\n",
      "2025-04-25 22:34:53,073 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,074 - INFO -     Set cell H9 to 2\n",
      "2025-04-25 22:34:53,074 - INFO - Processing Category C on row 10\n",
      "2025-04-25 22:34:53,074 - INFO -   Processing bundle: Solo Feast\n",
      "2025-04-25 22:34:53,075 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,075 - INFO -     Set cell B10 to 1\n",
      "2025-04-25 22:34:53,075 - INFO -   Processing bundle: Couple's Delight\n",
      "2025-04-25 22:34:53,076 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,076 - INFO -     Set cell D10 to 1\n",
      "2025-04-25 22:34:53,076 - INFO -   Processing bundle: Phuket Flavors Sampler\n",
      "2025-04-25 22:34:53,076 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,077 - INFO -     Set cell F10 to 2\n",
      "2025-04-25 22:34:53,077 - INFO -   Processing bundle: Southern Grand Feast\n",
      "2025-04-25 22:34:53,077 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,078 - INFO -     Set cell H10 to 2\n",
      "2025-04-25 22:34:53,078 - INFO - Processing Category D on row 11\n",
      "2025-04-25 22:34:53,078 - INFO -   Processing bundle: Solo Feast\n",
      "2025-04-25 22:34:53,079 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,079 - INFO -     Set cell B11 to 1\n",
      "2025-04-25 22:34:53,079 - INFO -   Processing bundle: Couple's Delight\n",
      "2025-04-25 22:34:53,080 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,080 - INFO -     Set cell D11 to 3\n",
      "2025-04-25 22:34:53,080 - INFO -   Processing bundle: Phuket Flavors Sampler\n",
      "2025-04-25 22:34:53,080 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,081 - INFO -     Set cell F11 to 6\n",
      "2025-04-25 22:34:53,081 - INFO -   Processing bundle: Southern Grand Feast\n",
      "2025-04-25 22:34:53,081 - INFO -     Available categories: ['Category A', 'Category B', 'Category C', 'Category D']\n",
      "2025-04-25 22:34:53,081 - INFO -     Set cell H11 to 10\n",
      "2025-04-25 22:34:53,248 - INFO - 'Menu Items' sheet created. Last populated row: 93\n",
      "2025-04-25 22:34:53,248 - INFO - Attempting to save workbook to: /Users/Cwkf_89/Documents/GitHub/hungryhub_automation/HH_Proposal_Generated.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'HH_Proposal_Generated.xlsx' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openpyxl\n",
    "import os\n",
    "import re # Import the regular expression module\n",
    "from openpyxl.styles import PatternFill, Font, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.cell.cell import MergedCell\n",
    "import logging # Use logging for better messages\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def parse_menu_items(file_path='./categorized_menu_items.txt'):\n",
    "    \"\"\"\n",
    "    Parse the categorized menu items text file, expecting format:\n",
    "    $Price - Item Name (Category)\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the text file containing categorized menu items\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with price categories ('Category A', etc.) as keys\n",
    "            and lists of menu item dicts ({'name': str, 'price': float, 'category': str}) as values.\n",
    "    \"\"\"\n",
    "    # These keys represent the PRICE BANDS (A, B, C, D) determined by the other script\n",
    "    menu_items_by_price_band = {\n",
    "        \"Category A\": [],\n",
    "        \"Category B\": [],\n",
    "        \"Category C\": [],\n",
    "        \"Category D\": []\n",
    "    }\n",
    "\n",
    "    absolute_path = os.path.abspath(file_path)\n",
    "    logging.info(f\"Attempting to read menu items from: {absolute_path}\")\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(absolute_path):\n",
    "            raise FileNotFoundError(f\"File not found at {absolute_path}\")\n",
    "\n",
    "        current_price_band = None # e.g., \"Category A\", \"Category B\"\n",
    "        items_parsed_count = 0\n",
    "\n",
    "        # Regex to capture Name and Category from \"Name (Category)\" format\n",
    "        # Allows for spaces in name and category. Handles optional space before parenthesis.\n",
    "        # Group 1: Item Name (non-greedy)\n",
    "        # Group 2: Semantic Category (inside parentheses)\n",
    "        name_category_pattern = re.compile(r'^(.*?)\\s*\\(([^)]+)\\)$')\n",
    "\n",
    "        with open(absolute_path, 'r', encoding='utf-8') as file:\n",
    "            for line_num, line in enumerate(file, 1):\n",
    "                line = line.strip()\n",
    "\n",
    "                # Skip empty lines or separator/header lines\n",
    "                if not line or line.startswith('====='):\n",
    "                    continue\n",
    "\n",
    "                # Check if this is a PRICE BAND header line (e.g., ----- Category A -----)\n",
    "                if line.startswith('----- Category'):\n",
    "                    try:\n",
    "                        # Extract price band character (A, B, C, or D)\n",
    "                        band_char = line.split('Category ')[1].strip()[0]\n",
    "                        current_price_band = f\"Category {band_char}\"\n",
    "                        if current_price_band not in menu_items_by_price_band:\n",
    "                            logging.warning(f\"Line {line_num}: Found unexpected price band '{current_price_band}'. Ignoring section.\")\n",
    "                            current_price_band = None # Reset if band is not A, B, C, or D\n",
    "                        else:\n",
    "                            logging.info(f\"Line {line_num}: Found Price Band Header '{current_price_band}'\")\n",
    "                    except IndexError:\n",
    "                        logging.warning(f\"Line {line_num}: Malformed price band header: '{line}'. Ignoring.\")\n",
    "                        current_price_band = None\n",
    "\n",
    "                # Check if this is a menu item line (starts with '$') and we are inside a valid price band\n",
    "                elif line.startswith('$') and current_price_band:\n",
    "                    try:\n",
    "                        # Split the line at the first \" - \" to separate price from name+category\n",
    "                        parts = line.split(' - ', 1)\n",
    "                        if len(parts) == 2:\n",
    "                            price_str = parts[0].strip()\n",
    "                            name_and_category_str = parts[1].strip()\n",
    "\n",
    "                            # Convert price string to number\n",
    "                            price_value = float(price_str.replace('$', '').replace(',', ''))\n",
    "\n",
    "                            # Now, parse the \"Item Name (Category)\" part\n",
    "                            match = name_category_pattern.match(name_and_category_str)\n",
    "                            if match:\n",
    "                                item_name = match.group(1).strip() # Extract name\n",
    "                                semantic_category = match.group(2).strip() # Extract category from parentheses\n",
    "                            else:\n",
    "                                # If format doesn't match \"Name (Category)\", treat whole string as name\n",
    "                                # and assign a default category. Log a warning.\n",
    "                                logging.warning(f\"Line {line_num}: Item format mismatch. Expected '$Price - Name (Category)', got '$Price - {name_and_category_str}'. Using full string as name and 'Uncategorized'.\")\n",
    "                                item_name = name_and_category_str\n",
    "                                semantic_category = \"Uncategorized\" # Default semantic category\n",
    "\n",
    "                            # Append the item data (including semantic category) to the current price band list\n",
    "                            menu_items_by_price_band[current_price_band].append({\n",
    "                                'name': item_name,\n",
    "                                'price': price_value,\n",
    "                                'category': semantic_category  # Store the extracted semantic category\n",
    "                            })\n",
    "                            items_parsed_count += 1\n",
    "                        else:\n",
    "                            logging.warning(f\"Line {line_num}: Malformed item line. Expected format '$Price - Name (Category)', got: '{line}'.\")\n",
    "                    except ValueError:\n",
    "                        logging.warning(f\"Line {line_num}: Could not parse price from '{price_str}'. Skipping item: '{line}'.\")\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Line {line_num}: Error processing item line: '{line}'. Error: {e}\", exc_info=True)\n",
    "                elif current_price_band and line: # If inside a band but line doesn't start with '$'\n",
    "                    logging.info(f\"Line {line_num}: Skipping non-item line within {current_price_band}: '{line}'\")\n",
    "\n",
    "\n",
    "        if items_parsed_count > 0:\n",
    "            logging.info(f\"Successfully parsed {items_parsed_count} menu items from {file_path}\")\n",
    "        else:\n",
    "            logging.warning(f\"No menu items were successfully parsed from {file_path}. Check file format or content.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"{e}\")\n",
    "        logging.warning(\"Using default menu items because the file could not be read.\")\n",
    "        # Add default items WITH the 'category' key\n",
    "        menu_items_by_price_band[\"Category A\"] = [\n",
    "            {\"name\": \"Default BBQ ribs\", \"price\": 700.0, \"category\": \"Main Course\"},\n",
    "            {\"name\": \"Default Chimichurri steak\", \"price\": 590.0, \"category\": \"Main Course\"},\n",
    "        ]\n",
    "        menu_items_by_price_band[\"Category B\"] = [\n",
    "            {\"name\": \"Default Milk Shakes\", \"price\": 190.0, \"category\": \"Beverage\"},\n",
    "        ]\n",
    "        menu_items_by_price_band[\"Category C\"] = [\n",
    "            {\"name\": \"Default Strawberry blast\", \"price\": 100.0, \"category\": \"Beverage\"},\n",
    "        ]\n",
    "        menu_items_by_price_band[\"Category D\"] = [\n",
    "            {\"name\": \"Default Extra shot\", \"price\": 25.0, \"category\": \"Add-on\"},\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred while reading menu items file: {e}\", exc_info=True)\n",
    "        logging.warning(\"Using default menu items due to the error.\")\n",
    "        # Populate with defaults including category key\n",
    "        menu_items_by_price_band[\"Category A\"] = [{\"name\": \"Error Default A\", \"price\": 1.0, \"category\": \"Error\"}]\n",
    "        menu_items_by_price_band[\"Category B\"] = [{\"name\": \"Error Default B\", \"price\": 1.0, \"category\": \"Error\"}]\n",
    "        menu_items_by_price_band[\"Category C\"] = [{\"name\": \"Error Default C\", \"price\": 1.0, \"category\": \"Error\"}]\n",
    "        menu_items_by_price_band[\"Category D\"] = [{\"name\": \"Error Default D\", \"price\": 1.0, \"category\": \"Error\"}]\n",
    "\n",
    "\n",
    "    # Print summary of parsed items\n",
    "    logging.info(\"--- Parsed Menu Items Summary (by Price Band) ---\")\n",
    "    for price_band, items in menu_items_by_price_band.items():\n",
    "        logging.info(f\"  {price_band}: {len(items)} items\")\n",
    "        # Optional: Print first few items for verification\n",
    "        # for item in items[:2]:\n",
    "        #      logging.info(f\"    - {item['name']} (${item['price']}) ({item['category']})\")\n",
    "        # if len(items) > 2:\n",
    "        #      logging.info(\"    - ...\")\n",
    "    logging.info(\"-------------------------------------------------\")\n",
    "\n",
    "    return menu_items_by_price_band # Return the dictionary structured by price bands\n",
    "\n",
    "\n",
    "def create_menu_sheet(workbook, menu_items_by_price_band):\n",
    "    \"\"\"\n",
    "    Creates the 'Menu Items' sheet in the workbook.\n",
    "    Column A ('Category') now uses the semantic category parsed from the file.\n",
    "\n",
    "    Args:\n",
    "        workbook: The openpyxl workbook to modify\n",
    "        menu_items_by_price_band: Dictionary structured by price bands ('Category A', 'B', etc.),\n",
    "                                containing lists of item dictionaries\n",
    "                                {'name': str, 'price': float, 'category': str}.\n",
    "    \"\"\"\n",
    "    menu_sheet = workbook.create_sheet(title='Menu Items')\n",
    "\n",
    "    # --- Styles (same as before) ---\n",
    "    red_fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "    light_yellow_fill = PatternFill(start_color=\"FFFFD4\", end_color=\"FFFFD4\", fill_type=\"solid\")\n",
    "    white_font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
    "    bold_font = Font(bold=True)\n",
    "    center_aligned = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "    left_aligned = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "    # --- Sheet Headers and Setup (same as before) ---\n",
    "    menu_sheet.merge_cells('A1:E1')\n",
    "    header_cell = menu_sheet['A1']\n",
    "    header_cell.value = \"Hungry Hub Menu Sections\"\n",
    "    header_cell.fill = red_fill; header_cell.font = white_font; header_cell.alignment = center_aligned\n",
    "    menu_sheet.row_dimensions[1].height = 25\n",
    "\n",
    "    menu_sheet['G1'] = \"Formula to Calculate NET Price for Menu\"\n",
    "    menu_sheet['G3'] = \"VAT (Extra)\"; menu_sheet['I3'] = \"7%\"\n",
    "    menu_sheet['G4'] = \"Service (Extra)\"; menu_sheet['I4'] = \"10%\"\n",
    "    menu_sheet['G6'] = \"You can Adjust\"\n",
    "\n",
    "    column_headers = [\n",
    "        \"Category\", # This column will now show the SEMANTIC category (Appetizer, Main, etc.)\n",
    "        \"Menu Name (English)\",\n",
    "        \"Description (English or Thai) or Menu Name (Thai)\", # Keeping as placeholder\n",
    "        \"Menu Price\",\n",
    "        \"Price (NET) (Formula)\"\n",
    "    ]\n",
    "    for col, header in enumerate(column_headers, start=1):\n",
    "        cell = menu_sheet.cell(row=2, column=col)\n",
    "        cell.value = header; cell.font = bold_font; cell.alignment = center_aligned; cell.border = border\n",
    "    menu_sheet.row_dimensions[2].height = 20\n",
    "\n",
    "    menu_sheet.column_dimensions['A'].width = 25\n",
    "    menu_sheet.column_dimensions['B'].width = 40\n",
    "    menu_sheet.column_dimensions['C'].width = 40\n",
    "    menu_sheet.column_dimensions['D'].width = 15\n",
    "    menu_sheet.column_dimensions['E'].width = 15\n",
    "\n",
    "    current_row = 3\n",
    "\n",
    "    # --- Populate Menu Items ---\n",
    "    # Iterate through the PRICE BANDS (A, B, C, D)\n",
    "    for price_band_key in [\"Category A\", \"Category B\", \"Category C\", \"Category D\"]:\n",
    "        # Add the Price Band header row (e.g., \"Category A\")\n",
    "        menu_sheet.merge_cells(start_row=current_row, start_column=1, end_row=current_row, end_column=5)\n",
    "        top_left_cell = menu_sheet.cell(row=current_row, column=1, value=price_band_key)\n",
    "        top_left_cell.fill = red_fill; top_left_cell.font = white_font; top_left_cell.alignment = center_aligned\n",
    "        menu_sheet.row_dimensions[current_row].height = 22\n",
    "        current_row += 1\n",
    "\n",
    "        # Get the list of items belonging to this price band\n",
    "        items_in_band = menu_items_by_price_band.get(price_band_key, [])\n",
    "\n",
    "        if not items_in_band:\n",
    "            logging.info(f\"No items found for Price Band {price_band_key} to populate in the 'Menu Items' sheet.\")\n",
    "            # Optionally add a placeholder row in the sheet\n",
    "            # menu_sheet.cell(row=current_row, column=1, value=f\"No items found in {price_band_key}\")\n",
    "            # menu_sheet.merge_cells(start_row=current_row, start_column=1, end_row=current_row, end_column=5)\n",
    "            # current_row += 1\n",
    "            continue # Skip to the next price band\n",
    "\n",
    "        # Add each menu item from the list for this band\n",
    "        for item_dict in items_in_band: # item_dict is {'name': ..., 'price': ..., 'category': ...}\n",
    "\n",
    "            # *** CHANGE HERE ***\n",
    "            # Column A: Use the actual SEMANTIC category parsed from the file\n",
    "            semantic_category = item_dict.get('category', 'Unknown') # Use .get for safety\n",
    "            cell = menu_sheet.cell(row=current_row, column=1, value=semantic_category)\n",
    "            cell.alignment = left_aligned\n",
    "            cell.border = border\n",
    "\n",
    "            # Column B: Menu Name (English) - From parsed data\n",
    "            cell = menu_sheet.cell(row=current_row, column=2, value=item_dict.get('name', 'N/A'))\n",
    "            cell.alignment = left_aligned\n",
    "            cell.border = border\n",
    "\n",
    "            # Column C: Description (Thai) - Placeholder (remains unchanged)\n",
    "            cell = menu_sheet.cell(row=current_row, column=3, value=\"\")\n",
    "            cell.alignment = left_aligned\n",
    "            cell.border = border\n",
    "\n",
    "            # Column D: Menu Price - From parsed data\n",
    "            price = item_dict.get('price', 0.0)\n",
    "            cell = menu_sheet.cell(row=current_row, column=4, value=price)\n",
    "            cell.number_format = '#,##0.00'; cell.alignment = center_aligned; cell.border = border\n",
    "\n",
    "            # Column E: Price (NET) - Calculated (remains unchanged)\n",
    "            net_price = round(price * 1.177)\n",
    "            cell = menu_sheet.cell(row=current_row, column=5, value=net_price)\n",
    "            cell.number_format = '#,##0'; cell.alignment = center_aligned; cell.border = border\n",
    "\n",
    "            # Optional: Alternating row fill\n",
    "            # if current_row % 2 == 0:\n",
    "            #     fill_to_apply = light_yellow_fill\n",
    "            #     for col_idx in range(1, 6):\n",
    "            #         menu_sheet.cell(row=current_row, column=col_idx).fill = fill_to_apply\n",
    "\n",
    "            current_row += 1\n",
    "\n",
    "    logging.info(f\"'Menu Items' sheet created. Last populated row: {current_row - 1}\")\n",
    "    return menu_sheet\n",
    "\n",
    "\n",
    "def create_hungry_hub_proposal(json_file='./menu_bundles.json', menu_file='./categorized_menu_items.txt', output_file='HH_Proposal_Generated.xlsx'):\n",
    "    \"\"\"\n",
    "    Creates the main Excel proposal file with both sheets.\n",
    "    Uses the updated parse_menu_items and create_menu_sheet functions.\n",
    "    \"\"\"\n",
    "    # Step 1: Read bundle data (No changes needed here)\n",
    "    try:\n",
    "        json_abs_path = os.path.abspath(json_file)\n",
    "        logging.info(f\"Attempting to read bundles from: {json_abs_path}\")\n",
    "        with open(json_abs_path, 'r', encoding='utf-8') as file:\n",
    "            menu_bundles = json.load(file)\n",
    "        logging.info(f\"Successfully loaded {len(menu_bundles)} bundles from {json_file}\")\n",
    "        if len(menu_bundles) < 4:\n",
    "            logging.warning(f\"JSON file contains only {len(menu_bundles)} bundles, template expects 4.\")\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        logging.error(f\"Error reading JSON file '{json_file}': {e}\")\n",
    "        logging.warning(\"Using default menu bundles as fallback.\")\n",
    "        # Default bundles definition (no changes needed)\n",
    "        menu_bundles = [\n",
    "            { \"bundle_name\": \"Default A\", \"suggested_bundle_price\": \"$3000\", \"number_of_diners\": 6, \"category_portions\": {\"Category A\": 3, \"Category B\": 4, \"Category C\": 2, \"Category D\": 1}, \"original_bundle_price\": \"$3500\", \"discount_percentage\": \"15%\", \"price_per_diner\": \"$500\" },\n",
    "            { \"bundle_name\": \"Default B\", \"suggested_bundle_price\": \"$4000\", \"number_of_diners\": 8, \"category_portions\": {\"Category A\": 4, \"Category B\": 6, \"Category C\": 3, \"Category D\": 2}, \"original_bundle_price\": \"$4800\", \"discount_percentage\": \"20%\", \"price_per_diner\": \"$500\" },\n",
    "            { \"bundle_name\": \"Default C\", \"suggested_bundle_price\": \"$5000\", \"number_of_diners\": 10, \"category_portions\": {\"Category A\": 5, \"Category B\": 8, \"Category C\": 4, \"Category D\": 3}, \"original_bundle_price\": \"$6000\", \"discount_percentage\": \"17%\", \"price_per_diner\": \"$500\" },\n",
    "            { \"bundle_name\": \"Default D\", \"suggested_bundle_price\": \"$6000\", \"number_of_diners\": 12, \"category_portions\": {\"Category A\": 6, \"Category B\": 10, \"Category C\": 5, \"Category D\": 4}, \"original_bundle_price\": \"$7200\", \"discount_percentage\": \"17%\", \"price_per_diner\": \"$500\" }\n",
    "        ]\n",
    "        menu_bundles = menu_bundles[:4] # Ensure exactly 4\n",
    "\n",
    "\n",
    "    # *** Step 2: Parse menu items using the UPDATED parser ***\n",
    "    # This will now return the data structure including the semantic category\n",
    "    menu_items_data = parse_menu_items(menu_file)\n",
    "\n",
    "    # Step 3: Create Workbook and 'HH Proposal' Sheet (No changes needed here)\n",
    "    workbook = openpyxl.Workbook()\n",
    "    worksheet = workbook.active\n",
    "    worksheet.title = 'HH Proposal'\n",
    "\n",
    "    # Step 4: Define styles (No changes needed here)\n",
    "    red_fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "    light_yellow_fill = PatternFill(start_color=\"FFFFD4\", end_color=\"FFFFD4\", fill_type=\"solid\")\n",
    "    bright_yellow_fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "    white_font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
    "    bold_font = Font(bold=True)\n",
    "    center_aligned = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "    left_aligned = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "    # --- Populate 'HH Proposal' Sheet (No changes needed in this block) ---\n",
    "    # Header\n",
    "    worksheet.merge_cells('A1:I1')\n",
    "    header_cell = worksheet['A1']; header_cell.value = \"Hungry Hub PARTY PACK PROPOSAL\"\n",
    "    header_cell.fill = red_fill; header_cell.font = white_font; header_cell.alignment = center_aligned\n",
    "    worksheet.row_dimensions[1].height = 25\n",
    "    # Restaurant Name\n",
    "    worksheet['A2'] = \"Restaurant Name:\"; worksheet['A2'].font = bold_font\n",
    "    worksheet.merge_cells('B2:I2'); worksheet['B2'] = \"!!!--- Please Change Restaurant Name Here ---!!!\"\n",
    "    worksheet['B2'].alignment = center_aligned; worksheet['B2'].font = Font(bold=True, color=\"FF0000\")\n",
    "    # Package Names Row 3\n",
    "    worksheet['A3'] = \"Package Name:\"; worksheet['A3'].font = bold_font\n",
    "    pack_definitions = [\n",
    "        {\"name\": \"Pack A\", \"columns\": \"B:C\", \"bundle_index\": 0},\n",
    "        {\"name\": \"Pack B\", \"columns\": \"D:E\", \"bundle_index\": 1},\n",
    "        {\"name\": \"Pack C\", \"columns\": \"F:G\", \"bundle_index\": 2},\n",
    "        {\"name\": \"Pack D\", \"columns\": \"H:I\", \"bundle_index\": 3}\n",
    "    ]\n",
    "    for pack in pack_definitions:\n",
    "        cell_range = f\"{pack['columns'].split(':')[0]}3:{pack['columns'].split(':')[1]}3\"\n",
    "        worksheet.merge_cells(cell_range)\n",
    "        cell = worksheet[cell_range.split(':')[0]]\n",
    "        bundle_name = menu_bundles[pack['bundle_index']].get('bundle_name', pack['name'])\n",
    "        cell.value = bundle_name; cell.alignment = center_aligned; cell.font = bold_font\n",
    "    # HH Selling Price (NET) Row 4\n",
    "    worksheet['A4'] = \"HH Selling Price (NET)\"; worksheet['A4'].font = bold_font\n",
    "    for pack in pack_definitions:\n",
    "        col_start, col_end = pack['columns'].split(':')\n",
    "        cell_range = f\"{col_start}4:{col_end}4\"; worksheet.merge_cells(cell_range)\n",
    "\n",
    "        # *** FIX 1 START ***\n",
    "        price_value_raw = menu_bundles[pack['bundle_index']].get('suggested_bundle_price', 0) # Default to number 0\n",
    "        price = 0.0 # Initialize price\n",
    "        try:\n",
    "            if isinstance(price_value_raw, str):\n",
    "                # If it's a string, clean it\n",
    "                price = float(price_value_raw.replace('$', '').replace(',', ''))\n",
    "            elif isinstance(price_value_raw, (int, float)):\n",
    "                # If it's already a number, use it directly (ensure float)\n",
    "                price = float(price_value_raw)\n",
    "            else:\n",
    "                # Handle unexpected types if necessary\n",
    "                logging.warning(f\"Unexpected type for suggested_bundle_price: {type(price_value_raw)}. Using 0.\")\n",
    "                price = 0.0\n",
    "        except ValueError:\n",
    "            logging.warning(f\"Could not convert suggested_bundle_price '{price_value_raw}' to float. Using 0.\")\n",
    "            price = 0.0\n",
    "        # *** FIX 1 END ***\n",
    "\n",
    "        cell = worksheet[col_start + '4']\n",
    "        cell.value = price\n",
    "        cell.number_format = '#,##0'; cell.alignment = center_aligned; cell.fill = light_yellow_fill\n",
    "\n",
    "    # Max Diners Row 5 (No changes needed here)\n",
    "    worksheet['A5'] = \"Max Diners / Set\"; worksheet['A5'].font = bold_font\n",
    "    for pack in pack_definitions:\n",
    "        col_start, col_end = pack['columns'].split(':')\n",
    "        cell_range = f\"{col_start}5:{col_end}5\"; worksheet.merge_cells(cell_range)\n",
    "        diners = menu_bundles[pack['bundle_index']].get('number_of_diners', 0)\n",
    "        cell = worksheet[col_start + '5']\n",
    "        cell.value = diners; cell.number_format = '0'; cell.alignment = center_aligned; cell.fill = light_yellow_fill\n",
    "\n",
    "    # Remarks Row 6 (No changes needed here)\n",
    "    worksheet['A6'] = \"Remarks\"; worksheet['A6'].font = bold_font\n",
    "    for pack in pack_definitions:\n",
    "        col_start, col_end = pack['columns'].split(':')\n",
    "        cell_range = f\"{col_start}6:{col_end}6\"; worksheet.merge_cells(cell_range)\n",
    "        worksheet[col_start + '6'] = \"1 Water / Person\"; worksheet[col_start + '6'].alignment = center_aligned\n",
    "\n",
    "    # Menu Section Header Row 7 (No changes needed here)\n",
    "    worksheet.merge_cells('A7:I7')\n",
    "    menu_header = worksheet['A7']; menu_header.value = \"Menu Section (portions from each section) - See Menu In Next Sheet\"\n",
    "    menu_header.fill = red_fill; menu_header.font = white_font; menu_header.alignment = center_aligned\n",
    "    worksheet.row_dimensions[7].height = 25\n",
    "\n",
    "    # Category Rows 8-11 - UPDATED with more detailed logging and improved handling\n",
    "    group_rows = {\"Category A\": 8, \"Category B\": 9, \"Category C\": 10, \"Category D\": 11}\n",
    "    for category_band, row in group_rows.items():\n",
    "        worksheet[f'A{row}'] = category_band\n",
    "        worksheet[f'A{row}'].font = bold_font\n",
    "        \n",
    "        # Add debug logging to see what's happening\n",
    "        logging.info(f\"Processing {category_band} on row {row}\")\n",
    "        \n",
    "        for pack in pack_definitions:\n",
    "            col_start, col_end = pack['columns'].split(':')\n",
    "            cell_range = f\"{col_start}{row}:{col_end}{row}\"\n",
    "            worksheet.merge_cells(cell_range)\n",
    "            \n",
    "            bundle_data = menu_bundles[pack['bundle_index']]\n",
    "            bundle_name = bundle_data.get('bundle_name', f\"Bundle {pack['bundle_index'] + 1}\")\n",
    "            \n",
    "            # Debug what's in the bundle data\n",
    "            logging.info(f\"  Processing bundle: {bundle_name}\")\n",
    "            \n",
    "            # Initialize portions to 0\n",
    "            portions = 0\n",
    "            \n",
    "            # More robust checking for category_portions structure\n",
    "            if 'category_portions' in bundle_data:\n",
    "                if isinstance(bundle_data['category_portions'], dict):\n",
    "                    # Debug what categories exist in the portions dict\n",
    "                    logging.info(f\"    Available categories: {list(bundle_data['category_portions'].keys())}\")\n",
    "                    \n",
    "                    # Try exact match first\n",
    "                    if category_band in bundle_data['category_portions']:\n",
    "                        portions_raw = bundle_data['category_portions'][category_band]\n",
    "                        # Ensure portions is an integer\n",
    "                        try:\n",
    "                            portions = int(portions_raw)\n",
    "                        except (ValueError, TypeError):\n",
    "                            portions = 0\n",
    "                            logging.warning(f\"    Could not convert '{portions_raw}' to int for {category_band}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"    {category_band} not found in category_portions\")\n",
    "                else:\n",
    "                    logging.warning(f\"    category_portions is not a dict: {type(bundle_data['category_portions'])}\")\n",
    "            else:\n",
    "                logging.warning(f\"    No category_portions key found in bundle\")\n",
    "            \n",
    "            # Set the cell value AFTER merging\n",
    "            cell = worksheet[col_start + str(row)]\n",
    "            cell.value = portions\n",
    "            cell.number_format = '0'\n",
    "            cell.alignment = center_aligned\n",
    "            cell.fill = light_yellow_fill\n",
    "            \n",
    "            logging.info(f\"    Set cell {col_start}{row} to {portions}\")\n",
    "\n",
    "    # Total Dishes Row 12 (No changes needed here)\n",
    "    worksheet['A12'] = \"Total Dishes\"; worksheet['A12'].font = bold_font\n",
    "    for pack in pack_definitions:\n",
    "        col_start, col_end = pack['columns'].split(':')\n",
    "        cell_range = f\"{col_start}12:{col_end}12\"; worksheet.merge_cells(cell_range)\n",
    "        total_dishes = 0; bundle_data = menu_bundles[pack['bundle_index']]\n",
    "        if 'category_portions' in bundle_data and isinstance(bundle_data['category_portions'], dict):\n",
    "            total_dishes = sum(bundle_data['category_portions'].values())\n",
    "        cell = worksheet[f\"{col_start}12\"]\n",
    "        cell.value = total_dishes; cell.number_format = '0'; cell.alignment = center_aligned\n",
    "\n",
    "    # Avg Price Header Row 13 (No changes needed here)\n",
    "    worksheet.merge_cells('A13:I13')\n",
    "    price_header = worksheet['A13']; price_header.value = \"Average NET Selling Price / Discounts\"\n",
    "    price_header.fill = red_fill; price_header.font = white_font; price_header.alignment = center_aligned\n",
    "    worksheet.row_dimensions[13].height = 25\n",
    "\n",
    "    # Avg NET Selling Price Row 14 (Original Price)\n",
    "    worksheet['A14'] = \"Average NET Selling Price\"; worksheet['A14'].font = bold_font\n",
    "    for pack in pack_definitions:\n",
    "        col_start, col_end = pack['columns'].split(':')\n",
    "        cell_range = f\"{col_start}14:{col_end}14\"; worksheet.merge_cells(cell_range)\n",
    "\n",
    "        # *** FIX 2 START ***\n",
    "        price_value_raw = menu_bundles[pack['bundle_index']].get('original_bundle_price', 0) # Default to number 0\n",
    "        price = 0.0 # Initialize price\n",
    "        try:\n",
    "            if isinstance(price_value_raw, str):\n",
    "                # If it's a string, clean it\n",
    "                price = float(price_value_raw.replace('$', '').replace(',', ''))\n",
    "            elif isinstance(price_value_raw, (int, float)):\n",
    "                # If it's already a number, use it directly (ensure float)\n",
    "                price = float(price_value_raw)\n",
    "            else:\n",
    "                # Handle unexpected types if necessary\n",
    "                logging.warning(f\"Unexpected type for original_bundle_price: {type(price_value_raw)}. Using 0.\")\n",
    "                price = 0.0\n",
    "        except ValueError:\n",
    "            logging.warning(f\"Could not convert original_bundle_price '{price_value_raw}' to float. Using 0.\")\n",
    "            price = 0.0\n",
    "        # *** FIX 2 END ***\n",
    "\n",
    "        cell = worksheet[col_start + '14']\n",
    "        cell.value = price\n",
    "        cell.number_format = '#,##0'; cell.alignment = center_aligned\n",
    "\n",
    "    # Average Discount Row 15 (No changes needed here)\n",
    "    worksheet['A15'] = \"Average Discount\"; worksheet['A15'].font = bold_font\n",
    "    for pack in pack_definitions:\n",
    "        col_start, col_end = pack['columns'].split(':')\n",
    "        cell_range = f\"{col_start}15:{col_end}{15}\"; worksheet.merge_cells(cell_range)\n",
    "        discount_value_raw = menu_bundles[pack['bundle_index']].get('discount_percentage', '0%')\n",
    "        try:\n",
    "            if isinstance(discount_value_raw, str):\n",
    "                # If it's a string like \"15%\", clean and convert\n",
    "                discount_val = float(discount_value_raw.replace('%', '')) / 100.0\n",
    "                number_format = '0%'\n",
    "            elif isinstance(discount_value_raw, (int, float)):\n",
    "                # If it's already a number\n",
    "                discount_val = float(discount_value_raw)\n",
    "                # If the value is > 1, assume it's a percentage (e.g., 15 means 15%)\n",
    "                if discount_val > 1:\n",
    "                    discount_val = discount_val / 100.0\n",
    "                number_format = '0%'\n",
    "            else:\n",
    "                # Handle unexpected type\n",
    "                logging.warning(f\"Unexpected type for discount_percentage: {type(discount_value_raw)}. Using 0%.\")\n",
    "                discount_val = 0.0\n",
    "                number_format = '0%'\n",
    "        except ValueError:\n",
    "            # If conversion failed, use the original value as text\n",
    "            discount_val = discount_value_raw\n",
    "            number_format = '@'  # Text format\n",
    "        cell = worksheet[col_start + '15']\n",
    "        cell.value = discount_val; cell.number_format = number_format; cell.alignment = center_aligned\n",
    "\n",
    "    # Net Price Per Person Row 16\n",
    "    worksheet['A16'] = \"Net Price / Person\"; worksheet['A16'].font = bold_font\n",
    "    for pack in pack_definitions:\n",
    "        col_start, col_end = pack['columns'].split(':')\n",
    "        cell_range = f\"{col_start}16:{col_end}16\"; worksheet.merge_cells(cell_range)\n",
    "\n",
    "        # *** FIX 3 START (More robust handling) ***\n",
    "        price_per_diner_val = menu_bundles[pack['bundle_index']].get('price_per_diner', '0') # Default to string '0'\n",
    "        display_text = \"0 / Person\" # Default display text\n",
    "        try:\n",
    "            price_num = 0.0\n",
    "            if isinstance(price_per_diner_val, str):\n",
    "                # If it's a string like \"$500\" or \"500\", clean and convert\n",
    "                price_num = float(price_per_diner_val.replace('$', '').replace(',', ''))\n",
    "            elif isinstance(price_per_diner_val, (int, float)):\n",
    "                # If it's already a number\n",
    "                price_num = float(price_per_diner_val)\n",
    "            else:\n",
    "                # Handle unexpected type, keep price_num as 0.0\n",
    "                logging.warning(f\"Unexpected type for price_per_diner: {type(price_per_diner_val)}. Using 0.\")\n",
    "\n",
    "            display_text = f\"{price_num:,.0f} / Person\" # Format the extracted number\n",
    "\n",
    "        except ValueError:\n",
    "            # If conversion failed, use the original value (as string) in the display\n",
    "            logging.warning(f\"Could not convert price_per_diner '{price_per_diner_val}' to number. Displaying as is.\")\n",
    "            display_text = f\"{price_per_diner_val} / Person\"\n",
    "        except Exception as e:\n",
    "            # Catch potential formatting errors, though unlikely here\n",
    "            logging.error(f\"Error formatting price_per_diner '{price_per_diner_val}': {e}. Displaying as is.\")\n",
    "            display_text = f\"{price_per_diner_val} / Person\" # Fallback\n",
    "        # *** FIX 3 END ***\n",
    "\n",
    "        cell = worksheet[col_start + '16']\n",
    "        cell.value = display_text\n",
    "        cell.alignment = center_aligned; cell.fill = bright_yellow_fill; cell.font = bold_font\n",
    "    # Adjustment Info Rows 17-18\n",
    "    worksheet['A17'] = \"You can Adjust\"; worksheet['A17'].font = Font(italic=True)\n",
    "    worksheet['A18'] = \"Don't Adjust (Formula)\"; worksheet['A18'].font = Font(italic=True)\n",
    "    adjustable_rows = [4, 5]\n",
    "    for row in adjustable_rows:\n",
    "        for pack in pack_definitions:\n",
    "            col_start, col_end = pack['columns'].split(':'); worksheet[f\"{col_start}{row}\"].fill = light_yellow_fill\n",
    "    # Apply borders\n",
    "    for row in worksheet.iter_rows(min_row=1, max_row=18, min_col=1, max_col=9):\n",
    "        for cell in row:\n",
    "            is_merged = any(cell.coordinate in merged_range for merged_range in worksheet.merged_cells.ranges)\n",
    "            is_top_left = any(cell.coordinate == merged_range.coord.split(':')[0] for merged_range in worksheet.merged_cells.ranges if cell.coordinate in merged_range)\n",
    "            if not is_merged or is_top_left: cell.border = border\n",
    "    # Set column widths\n",
    "    worksheet.column_dimensions['A'].width = 25\n",
    "    for col_letter in ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']: worksheet.column_dimensions[col_letter].width = 15\n",
    "    # --- End Populating 'HH Proposal' Sheet ---\n",
    "\n",
    "\n",
    "    # *** Step 5: Create the menu sheet using the UPDATED sheet creator ***\n",
    "    # This function now expects the new data structure and uses the semantic category\n",
    "    create_menu_sheet(workbook, menu_items_data)\n",
    "\n",
    "    # Step 6: Save the workbook (No changes needed here)\n",
    "    try:\n",
    "        output_abs_path = os.path.abspath(output_file)\n",
    "        logging.info(f\"Attempting to save workbook to: {output_abs_path}\")\n",
    "        workbook.save(output_abs_path)\n",
    "        return f\"Excel file '{output_file}' has been created successfully.\"\n",
    "    except PermissionError:\n",
    "        logging.error(f\"Permission denied. Could not save '{output_file}'. Check if the file is open or permissions.\")\n",
    "        return f\"Error: Permission denied saving '{output_file}'.\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving Excel file '{output_file}': {e}\", exc_info=True)\n",
    "        return f\"Error saving Excel file '{output_file}': {e}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bundle_json_path = './menu_bundles.json'\n",
    "    # This is the text file generated by the *other* script\n",
    "    menu_items_text_path = './categorized_menu_items.txt'\n",
    "    output_excel_path = 'HH_Proposal_Generated.xlsx'\n",
    "\n",
    "    # --- Create a dummy categorized_menu_items.txt with the NEW format if it doesn't exist ---\n",
    "    if not os.path.exists(menu_items_text_path):\n",
    "        logging.warning(f\"'{menu_items_text_path}' not found. Creating a dummy file with the new format for testing.\")\n",
    "        try:\n",
    "            with open(menu_items_text_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"===== MENU ITEMS BY PRICE CATEGORY (Generated by Script) =====\\n\")\n",
    "                f.write(\"\\n----- Category A ($600.00 - $750.00) -----\\n\")\n",
    "                f.write(\"  $750.00 - Ribeye Steak (Main Course)\\n\")\n",
    "                f.write(\"  $600.00 - Lobster Bisque (Appetizer)\\n\")\n",
    "                f.write(\"\\n----- Category B ($200.00 - $200.00) -----\\n\")\n",
    "                f.write(\"  $200.00 - Grilled Chicken Sandwich (Main Course)\\n\")\n",
    "                f.write(\"\\n----- Category C ($150.00 - $150.00) -----\\n\")\n",
    "                f.write(\"  $150.00 - Chocolate Lava Cake (Dessert)\\n\")\n",
    "                f.write(\"  $150.00 - Caesar Salad (Appetizer)\\n\")\n",
    "                f.write(\"\\n----- Category D ($30.00 - $30.00) -----\\n\")\n",
    "                f.write(\"  $30.00 - Side of Fries (Side Dish)\\n\")\n",
    "                f.write(\"  $30.00 - Iced Tea (Beverage)\\n\")\n",
    "            logging.info(f\"Dummy '{menu_items_text_path}' created successfully.\")\n",
    "        except IOError as e:\n",
    "            logging.error(f\"Failed to create dummy menu items file: {e}\")\n",
    "\n",
    "\n",
    "    # Create a dummy menu_bundles.json if it doesn't exist (no changes needed here)\n",
    "    if not os.path.exists(bundle_json_path):\n",
    "        logging.warning(f\"'{bundle_json_path}' not found. Creating a dummy file for testing.\")\n",
    "        # Dummy bundle data (same as before)\n",
    "        dummy_bundles = [\n",
    "            { \"bundle_name\": \"Test Bundle A\", \"suggested_bundle_price\": \"$3100\", \"number_of_diners\": 6, \"category_portions\": {\"Category A\": 3, \"Category B\": 4, \"Category C\": 2, \"Category D\": 1}, \"original_bundle_price\": \"$3600\", \"discount_percentage\": \"14%\", \"price_per_diner\": \"$517\" },\n",
    "            { \"bundle_name\": \"Test Bundle B\", \"suggested_bundle_price\": \"$4100\", \"number_of_diners\": 8, \"category_portions\": {\"Category A\": 4, \"Category B\": 6, \"Category C\": 3, \"Category D\": 2}, \"original_bundle_price\": \"$4900\", \"discount_percentage\": \"16%\", \"price_per_diner\": \"$513\" },\n",
    "            { \"bundle_name\": \"Test Bundle C\", \"suggested_bundle_price\": \"$5100\", \"number_of_diners\": 10, \"category_portions\": {\"Category A\": 5, \"Category B\": 8, \"Category C\": 4, \"Category D\": 3}, \"original_bundle_price\": \"$6100\", \"discount_percentage\": \"16%\", \"price_per_diner\": \"$510\" },\n",
    "            { \"bundle_name\": \"Test Bundle D\", \"suggested_bundle_price\": \"$6100\", \"number_of_diners\": 12, \"category_portions\": {\"Category A\": 6, \"Category B\": 10, \"Category C\": 5, \"Category D\": 4}, \"original_bundle_price\": \"$7300\", \"discount_percentage\": \"16%\", \"price_per_diner\": \"$508\" }\n",
    "        ]\n",
    "        try:\n",
    "            with open(bundle_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(dummy_bundles, f, indent=4)\n",
    "            logging.info(f\"Dummy '{bundle_json_path}' created successfully.\")\n",
    "        except IOError as e:\n",
    "            logging.error(f\"Failed to create dummy bundles file: {e}\")\n",
    "\n",
    "\n",
    "    # Run the function to create the Excel file\n",
    "    result = create_hungry_hub_proposal(\n",
    "        json_file=bundle_json_path,\n",
    "        menu_file=menu_items_text_path,\n",
    "        output_file=output_excel_path\n",
    "    )\n",
    "    print(result) # Print final success/error message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is455_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
