{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Menu Items Extraction and Menu Categorisation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MENU ITEM EXTRACTION AND CATEGORIZATION =====\n",
      "Processing menu images from: ./test_menu/\n",
      "Target number of price categories: 4\n",
      "Found 11 images to process\n",
      "\n",
      "Processing image 1/11: Menu_6.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 4 menu items with prices\n",
      "Extraction rate: 50.0% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 4 unique menu items\n",
      "\n",
      "Processing image 2/11: Menu_7.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 6 menu items with prices\n",
      "Extraction rate: 100.0% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 10 unique menu items\n",
      "\n",
      "Processing image 3/11: Menu_5.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 22 menu items with prices\n",
      "Extraction rate: 100.0% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 32 unique menu items\n",
      "\n",
      "Processing image 4/11: Menu_4.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 6 menu items with prices\n",
      "Extraction rate: 100.0% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 38 unique menu items\n",
      "\n",
      "Processing image 5/11: Menu_1.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 28 menu items with prices\n",
      "Extraction rate: 96.6% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 66 unique menu items\n",
      "\n",
      "Processing image 6/11: Menu_3.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 20 menu items with prices\n",
      "Extraction rate: 90.9% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 86 unique menu items\n",
      "\n",
      "Processing image 7/11: Menu_2.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 2 menu items with prices\n",
      "Extraction rate: 18.2% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 88 unique menu items\n",
      "\n",
      "Processing image 8/11: Menu_11.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 3 menu items with prices\n",
      "Extraction rate: 50.0% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 73.3%\n",
      "Running total: 91 unique menu items\n",
      "\n",
      "Processing image 9/11: Menu_10.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 6 menu items with prices\n",
      "Extraction rate: 85.7% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 97 unique menu items\n",
      "\n",
      "Processing image 10/11: Menu_9.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 11 menu items with prices\n",
      "Extraction rate: 91.7% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 108 unique menu items\n",
      "\n",
      "Processing image 11/11: Menu_8.png\n",
      "Text extraction successful - analyzing content...\n",
      "Found 8 menu items with prices\n",
      "Extraction rate: 88.9% of non-empty lines contained recognizable menu items\n",
      "Average confidence score: 100.0%\n",
      "Running total: 116 unique menu items\n",
      "\n",
      "Extraction complete. Total unique menu items found: 116\n",
      "Overall extraction confidence: 99.3%\n",
      "\n",
      "Items extracted per image:\n",
      "  Menu_6.png: 4 items\n",
      "  Menu_7.png: 6 items\n",
      "  Menu_5.png: 22 items\n",
      "  Menu_4.png: 6 items\n",
      "  Menu_1.png: 28 items\n",
      "  Menu_3.png: 20 items\n",
      "  Menu_2.png: 2 items\n",
      "  Menu_11.png: 3 items\n",
      "  Menu_10.png: 6 items\n",
      "  Menu_9.png: 11 items\n",
      "  Menu_8.png: 8 items\n",
      "\n",
      "Price range: $1.00 to $800.00 (spread: $799.00)\n",
      "Large price range detected - using adaptive categorization\n",
      "Category boundaries: ['$240.00', '$97.00', '$20.00', '$0.99']\n",
      "Category A: 28 items, price range $250.00 - $800.00\n",
      "Category B: 30 items, price range $100.00 - $240.00\n",
      "Category C: 28 items, price range $25.00 - $97.00\n",
      "Category D: 30 items, price range $1.00 - $20.00\n",
      "\n",
      "Extraction Complete - Average confidence score: 99.3%\n",
      "\n",
      "========== MENU ITEMS BY PRICE CATEGORY ==========\n",
      "\n",
      "----- Category A ($250.00 - $800.00) -----\n",
      "28 items:\n",
      "  $800.00 - bbq ribs\n",
      "  $590.00 - Chimichurri steak\n",
      "  $500.00 - shrimp on toast\n",
      "  $500.00 - shrimp mayonnaise + herb yogurt\n",
      "  $420.00 - roasted pork chop\n",
      "  $340.00 - cured salmon & dill cream\n",
      "  $320.00 - Caramel popcorn, peach melba, cookies & brownies\n",
      "  $320.00 - shrimp linguine\n",
      "  $300.00 - egg & avocado\n",
      "  $300.00 - croque madame\n",
      "  $285.00 - Strawberry french toast\n",
      "  $285.00 - chocolate skillet cookie\n",
      "  $285.00 - brown butter brownie\n",
      "  $285.00 - vongole pasta\n",
      "  $280.00 - ragu pasta\n",
      "  $280.00 - tomato & burrata\n",
      "  $275.00 - mushroom pesto\n",
      "  $275.00 - chilli bacon spaghetti\n",
      "  $270.00 - Strawberry crepes\n",
      "  $265.00 - apple crumble\n",
      "  $265.00 - golden almond crumble\n",
      "  $260.00 - spaghetti carbonara\n",
      "  $260.00 - lay low breakfast\n",
      "  $260.00 - grilled cheese toast\n",
      "  $250.00 - Banana french toast\n",
      "  $250.00 - Banana crepes\n",
      "  $250.00 - sticky toffee pudding\n",
      "  $250.00 - soft medjool date cake\n",
      "\n",
      "----- Category B ($100.00 - $240.00) -----\n",
      "30 items:\n",
      "  $240.00 - Caesar salad\n",
      "  $240.00 - chicken & baby gem salad\n",
      "  $140.00 - caramel macchiato\n",
      "  $140.00 - affogato***\n",
      "  $140.00 - valrhona chocolate\n",
      "  $140.00 - matcha latte\n",
      "  $140.00 - thai tea latte\n",
      "  $140.00 - thai tea frappe\n",
      "  $130.00 - orangina espresso\n",
      "  $125.00 - caffe mocha\n",
      "  $120.00 - strawberry lemon soda\n",
      "  $120.00 - peach soda\n",
      "  $120.00 - mango passion fruit soda\n",
      "  $120.00 - lemonade soda\n",
      "  $120.00 - green tea\n",
      "  $120.00 - black rose tea\n",
      "  $120.00 - english breakfast tea\n",
      "  $120.00 - oolong chrysanthemum tea\n",
      "  $120.00 - earl grey tea\n",
      "  $120.00 - herbal blends tea\n",
      "  $110.00 - dirty\n",
      "  $110.00 - flat white (H)\n",
      "  $110.00 - cortado (H)\n",
      "  $110.00 - cappuccino (H)\n",
      "  $100.00 - Strawberry bliss\n",
      "  $100.00 - Strawberry\n",
      "  $100.00 - Banana\n",
      "  $100.00 - caffe latte\n",
      "  $100.00 - burrito\n",
      "  $100.00 - roasted salmon\n",
      "\n",
      "----- Category C ($25.00 - $97.00) -----\n",
      "28 items:\n",
      "  $97.00 - Chocolate cookie & cream\n",
      "  $95.00 - Oolong fresh\n",
      "  $95.00 - Chocolate fudge\n",
      "  $95.00 - Natural praline\n",
      "  $95.00 - Creamy banana\n",
      "  $95.00 - Mint chocolate chip\n",
      "  $95.00 - Green apple sorbet\n",
      "  $95.00 - Lemon fruit sorbet\n",
      "  $95.00 - Blood orange sorbet\n",
      "  $94.00 - Coffee peanut butter\n",
      "  $94.00 - Dark chocolate sorbet\n",
      "  $93.00 - Mango sorbet\n",
      "  $92.00 - Salted toffee coffee\n",
      "  $92.00 - Sea caramel\n",
      "  $90.00 - Raspberry sorbet\n",
      "  $85.00 - Strawberry banana\n",
      "  $85.00 - Coconut sorbet\n",
      "  $85.00 - americano\n",
      "  $81.00 - Strawberry sorbet\n",
      "  $80.00 - Madagascar vanilla\n",
      "  $70.00 - espresso (H)\n",
      "  $50.00 - special beans +\n",
      "  $40.00 - Caramel macchiato\n",
      "  $40.00 - Valrhona chocolate matcha latte\n",
      "  $40.00 - Caramel macchiato (variant 1)\n",
      "  $40.00 - Valrhona chocolate matcha latte (variant 1)\n",
      "  $25.00 - extra shot +\n",
      "  $25.00 - oat milk +\n",
      "\n",
      "----- Category D ($1.00 - $20.00) -----\n",
      "30 items:\n",
      "  $20.00 - A.B.C. (berry, bliss, cookie trio)\n",
      "  $20.00 - Americano\n",
      "  $20.00 - Caffe latte\n",
      "  $20.00 - Caffe mocha\n",
      "  $20.00 - Strawberry lemon soda\n",
      "  $20.00 - Peach soda\n",
      "  $20.00 - Mango passion fruit soda\n",
      "  $20.00 - Lemonade soda\n",
      "  $20.00 - Americano (variant 1)\n",
      "  $20.00 - Caffe latte (variant 1)\n",
      "  $20.00 - Caffe mocha (variant 1)\n",
      "  $20.00 - Strawberry lemon soda (variant 1)\n",
      "  $20.00 - Peach soda (variant 1)\n",
      "  $20.00 - Mango passion fruit soda (variant 1)\n",
      "  $20.00 - Lemonade soda (variant 1)\n",
      "  $9.00 - salmon poke\n",
      "  $9.00 - shrimp poke\n",
      "  $9.00 - chicken poke\n",
      "  $6.00 - poached egg\n",
      "  $5.90 - Milk Shakes\n",
      "  $5.00 - edamame\n",
      "  $4.80 - Floats\n",
      "  $3.20 - Sundae a.b.c\n",
      "  $3.20 - Berry bliss\n",
      "  $3.20 - Cookie trio\n",
      "  $3.00 - sourdough\n",
      "  $1.60 - Caramel popcorn\n",
      "  $1.60 - Peach melba\n",
      "  $1.60 - Cookies & brownies\n",
      "  $1.00 - avocado\n",
      "\n",
      "Results saved to categorized_menu_items.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "from anthropic import Anthropic\n",
    "from collections import defaultdict\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Encode an image file to base64.\n",
    "    \n",
    "    :param image_path: Path to the image file\n",
    "    :return: Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def extract_text_from_image(api_key, image_paths, prompt_text):\n",
    "    \"\"\"\n",
    "    Use Claude to extract text from multiple images.\n",
    "    \n",
    "    :param api_key: Your Anthropic API key\n",
    "    :param image_paths: List of paths to image files\n",
    "    :param prompt_text: Text prompt for Claude\n",
    "    :return: Extracted text from the images\n",
    "    \"\"\"\n",
    "    # Initialize the Anthropic client\n",
    "    client = Anthropic(api_key=api_key)\n",
    "    \n",
    "    try:\n",
    "        # Create content array\n",
    "        content = []\n",
    "        \n",
    "        # Add each image to the content array\n",
    "        for image_path in image_paths:\n",
    "            # Determine media type based on file extension\n",
    "            media_type = \"image/jpeg\"  # Default\n",
    "            if image_path.lower().endswith(\".png\"):\n",
    "                media_type = \"image/png\"\n",
    "            elif image_path.lower().endswith(\".gif\"):\n",
    "                media_type = \"image/gif\"\n",
    "            \n",
    "            # Encode the image\n",
    "            base64_image = encode_image(image_path)\n",
    "            \n",
    "            # Add image to content array\n",
    "            content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": media_type,\n",
    "                    \"data\": base64_image\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Add text prompt at the end\n",
    "        content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt_text\n",
    "        })\n",
    "        \n",
    "        # Send request to Claude\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=2500,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Return the extracted text\n",
    "        return response.content[0].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_menu_items(extracted_text):\n",
    "    \"\"\"\n",
    "    Parse menu items and their prices from extracted text.\n",
    "    \n",
    "    :param extracted_text: Text extracted from the image\n",
    "    :return: Dictionary of menu items and their prices, plus confidence scores\n",
    "    \"\"\"\n",
    "    menu_items = {}\n",
    "    confidence_scores = {}\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = extracted_text.split('\\n')\n",
    "    total_non_empty_lines = sum(1 for line in lines if line.strip())\n",
    "    successful_extractions = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        \n",
    "        line_confidence = 1.0  # Start with full confidence\n",
    "        \n",
    "        # Check for uncertainty indicators in the text\n",
    "        uncertainty_phrases = [\"unclear\", \"can't make out\", \"illegible\", \"not visible\", \"hard to read\", \"possibly\", \"maybe\", \"appears to be\"]\n",
    "        for phrase in uncertainty_phrases:\n",
    "            if phrase in line.lower():\n",
    "                line_confidence *= 0.6  # Reduce confidence if uncertainty is indicated\n",
    "        \n",
    "        # Look for price patterns with multiple formats\n",
    "        # This covers $10.99, $10, 10.99, €10.99, £10.99, etc.\n",
    "        price_match = re.search(r'(?:[$€£¥]\\s*)?(\\d+(?:,\\d{3})*(?:\\.\\d{1,2})?)', line)\n",
    "        \n",
    "        if price_match:\n",
    "            successful_extractions += 1\n",
    "            \n",
    "            # Extract the price and convert to float\n",
    "            price_str = price_match.group(1).replace(',', '')\n",
    "            price = float(price_str)\n",
    "            \n",
    "            # Extract the item name (everything before the price)\n",
    "            item_name = line[:price_match.start()].strip()\n",
    "            \n",
    "            # Clean up the item name (remove any dots, dashes or other separators)\n",
    "            item_name = re.sub(r'[.…\\-_]+\\s*$', '', item_name).strip()\n",
    "            \n",
    "            # Check name quality (short names might be incomplete)\n",
    "            if len(item_name) < 3:\n",
    "                line_confidence *= 0.7\n",
    "            \n",
    "            # Check price reasonableness (extremely low or high prices might be errors)\n",
    "            if price < 0.5 or price > 500:\n",
    "                line_confidence *= 0.6\n",
    "            \n",
    "            # If we have a valid item name and price, add to the dictionary\n",
    "            # Using a unique key if there are duplicate item names\n",
    "            if item_name and price > 0:\n",
    "                if item_name in menu_items:\n",
    "                    # If there's a duplicate, append a number to make it unique\n",
    "                    count = 1\n",
    "                    new_name = f\"{item_name} (variant {count})\"\n",
    "                    while new_name in menu_items:\n",
    "                        count += 1\n",
    "                        new_name = f\"{item_name} (variant {count})\"\n",
    "                    menu_items[new_name] = price\n",
    "                    confidence_scores[new_name] = line_confidence\n",
    "                else:\n",
    "                    menu_items[item_name] = price\n",
    "                    confidence_scores[item_name] = line_confidence\n",
    "    \n",
    "    # Calculate overall extraction quality metrics\n",
    "    extraction_rate = successful_extractions / total_non_empty_lines if total_non_empty_lines > 0 else 0\n",
    "    avg_confidence = sum(confidence_scores.values()) / len(confidence_scores) if confidence_scores else 0\n",
    "    \n",
    "    # Log the extraction metrics\n",
    "    print(f\"Found {len(menu_items)} menu items with prices\")\n",
    "    print(f\"Extraction rate: {extraction_rate:.1%} of non-empty lines contained recognizable menu items\")\n",
    "    print(f\"Average confidence score: {avg_confidence:.1%}\")\n",
    "    \n",
    "    return menu_items, confidence_scores\n",
    "\n",
    "def categorize_menu_items(menu_items, num_categories=3):\n",
    "    \"\"\"\n",
    "    Categorize menu items based on their price.\n",
    "    \n",
    "    :param menu_items: Dictionary of menu items and their prices\n",
    "    :param num_categories: Number of price categories\n",
    "    :return: Dictionary of categories and their items\n",
    "    \"\"\"\n",
    "    if not menu_items:\n",
    "        return {}\n",
    "    \n",
    "    # Sort items by price\n",
    "    sorted_items = sorted(menu_items.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Determine price ranges for categories\n",
    "    prices = [price for _, price in sorted_items]\n",
    "    max_price = max(prices)\n",
    "    min_price = min(prices)\n",
    "    price_range = max_price - min_price\n",
    "    \n",
    "    # Log price range information\n",
    "    print(f\"\\nPrice range: ${min_price:.2f} to ${max_price:.2f} (spread: ${price_range:.2f})\")\n",
    "    \n",
    "    # Create categories based on price ranges\n",
    "    categories = defaultdict(list)\n",
    "    \n",
    "    # If there's only one category or all prices are the same\n",
    "    if num_categories <= 1 or price_range == 0:\n",
    "        for item, price in sorted_items:\n",
    "            categories['A'].append((item, price))\n",
    "        return categories\n",
    "    \n",
    "    # For large price ranges, use adaptive categorization\n",
    "    # Check if the price range is very large compared to the minimum price\n",
    "    large_range = price_range > min_price * 3  # If range is more than 3x the minimum price\n",
    "    \n",
    "    if large_range:\n",
    "        print(\"Large price range detected - using adaptive categorization\")\n",
    "        \n",
    "        # Use percentile-based categorization instead of equal divisions\n",
    "        # This handles outliers better\n",
    "        \n",
    "        # Sort prices\n",
    "        sorted_prices = sorted(prices, reverse=True)\n",
    "        num_items = len(sorted_prices)\n",
    "        \n",
    "        # Calculate boundary indices for each category\n",
    "        boundaries = []\n",
    "        for i in range(1, num_categories):\n",
    "            idx = int((i * num_items) / num_categories)\n",
    "            if idx < len(sorted_prices):\n",
    "                boundaries.append(sorted_prices[idx])\n",
    "        \n",
    "        # Add the minimum price as the last boundary\n",
    "        boundaries.append(min_price - 0.01)  # Slightly below min to include all items\n",
    "        \n",
    "        # Print the category boundaries\n",
    "        boundary_strs = [f\"${b:.2f}\" for b in boundaries]\n",
    "        print(f\"Category boundaries: {boundary_strs}\")\n",
    "        \n",
    "        # Assign items to categories\n",
    "        for item, price in sorted_items:\n",
    "            # Find which category this price belongs to\n",
    "            for i, boundary in enumerate(boundaries):\n",
    "                if price > boundary:\n",
    "                    category_letter = chr(65 + i)  # A, B, C, etc.\n",
    "                    categories[category_letter].append((item, price))\n",
    "                    break\n",
    "    else:\n",
    "        # Use standard equal division\n",
    "        category_range = price_range / num_categories\n",
    "        \n",
    "        for item, price in sorted_items:\n",
    "            # Determine which category this item belongs to\n",
    "            category_index = min(num_categories - 1, int((max_price - price) / category_range))\n",
    "            category_letter = chr(65 + category_index)  # A, B, C, etc.\n",
    "            categories[category_letter].append((item, price))\n",
    "    \n",
    "    # Log the distribution of items across categories\n",
    "    for category, items in sorted(categories.items()):\n",
    "        category_min = min([price for _, price in items]) if items else 0\n",
    "        category_max = max([price for _, price in items]) if items else 0\n",
    "        print(f\"Category {category}: {len(items)} items, price range ${category_min:.2f} - ${category_max:.2f}\")\n",
    "    \n",
    "    return categories\n",
    "\n",
    "def process_menu_images(api_key, image_folder, num_categories=3):\n",
    "    \"\"\"\n",
    "    Process all menu images in a folder and categorize items by price.\n",
    "    \n",
    "    :param api_key: Your Anthropic API key\n",
    "    :param image_folder: Path to folder containing menu images\n",
    "    :param num_categories: Number of price categories\n",
    "    :return: Categorized menu items and confidence scores\n",
    "    \"\"\"\n",
    "    # List all image files in the folder\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif']\n",
    "    image_paths = []\n",
    "    \n",
    "    for file in os.listdir(image_folder):\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            image_paths.append(os.path.join(image_folder, file))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No image files found in {image_folder}\")\n",
    "        return {}, {}\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images to process\")\n",
    "    \n",
    "    # Process images one by one to avoid hitting API limits\n",
    "    all_menu_items = {}\n",
    "    all_confidence_scores = {}\n",
    "    image_extraction_rates = []\n",
    "    \n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        print(f\"\\nProcessing image {idx+1}/{len(image_paths)}: {os.path.basename(image_path)}\")\n",
    "        prompt_text = \"\"\"\n",
    "        Please extract all menu items and their prices from this image. \n",
    "        Format each item on a new line with the item name followed by the price.\n",
    "        Include EVERY menu item and price visible in the image.\n",
    "        For each item, include:\n",
    "        1. The complete item name\n",
    "        2. The exact price (with currency symbol if present)\n",
    "        \n",
    "        If text is unclear or you're uncertain about an item or price, please indicate this \n",
    "        by adding \"(unclear)\" after the item.\n",
    "        \n",
    "        Example format:\n",
    "        Chicken Caesar Salad $12.99\n",
    "        Margherita Pizza $14.50\n",
    "        House Special (unclear) $16.99\n",
    "        \"\"\"\n",
    "        \n",
    "        extracted_text = extract_text_from_image(api_key, [image_path], prompt_text)\n",
    "        \n",
    "        if extracted_text:\n",
    "            print(f\"Text extraction successful - analyzing content...\")\n",
    "            \n",
    "            # Parse menu items and prices\n",
    "            menu_items, confidence_scores = parse_menu_items(extracted_text)\n",
    "            \n",
    "            # Store extraction rate for this image\n",
    "            image_name = os.path.basename(image_path)\n",
    "            image_extraction_rates.append((image_name, len(menu_items)))\n",
    "            \n",
    "            # Add to overall menu items, avoid overwriting duplicates\n",
    "            for item, price in menu_items.items():\n",
    "                if item in all_menu_items and all_menu_items[item] != price:\n",
    "                    # If same item has different price, make it unique\n",
    "                    new_item = f\"{item} ({os.path.basename(image_path)})\"\n",
    "                    all_menu_items[new_item] = price\n",
    "                    all_confidence_scores[new_item] = confidence_scores[item]\n",
    "                else:\n",
    "                    all_menu_items[item] = price\n",
    "                    all_confidence_scores[item] = confidence_scores[item]\n",
    "            \n",
    "            print(f\"Running total: {len(all_menu_items)} unique menu items\")\n",
    "        else:\n",
    "            print(f\"Failed to extract text from {os.path.basename(image_path)}\")\n",
    "    \n",
    "    # Print summary before categorization\n",
    "    print(f\"\\nExtraction complete. Total unique menu items found: {len(all_menu_items)}\")\n",
    "    \n",
    "    # Calculate average confidence score\n",
    "    if all_confidence_scores:\n",
    "        avg_confidence = sum(all_confidence_scores.values()) / len(all_confidence_scores)\n",
    "        print(f\"Overall extraction confidence: {avg_confidence:.1%}\")\n",
    "    \n",
    "    # Print extraction performance by image\n",
    "    print(\"\\nItems extracted per image:\")\n",
    "    for image_name, item_count in image_extraction_rates:\n",
    "        print(f\"  {image_name}: {item_count} items\")\n",
    "    \n",
    "    if not all_menu_items:\n",
    "        print(\"No menu items found in any images.\")\n",
    "        return {}, {}\n",
    "    \n",
    "    # Calculate a reasonable number of categories based on the number of items\n",
    "    if len(all_menu_items) < num_categories * 2:\n",
    "        adjusted_categories = max(1, len(all_menu_items) // 2)\n",
    "        if adjusted_categories != num_categories:\n",
    "            print(f\"Adjusting number of categories from {num_categories} to {adjusted_categories} based on item count\")\n",
    "            num_categories = adjusted_categories\n",
    "    \n",
    "    # Categorize menu items\n",
    "    categories = categorize_menu_items(all_menu_items, num_categories)\n",
    "    \n",
    "    return categories, all_confidence_scores\n",
    "\n",
    "def main():\n",
    "    # Replace with your actual Anthropic API key\n",
    "    API_KEY = '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'\n",
    "    \n",
    "    if not API_KEY:\n",
    "        print(\"Please set the ANTHROPIC_API_KEY environment variable.\")\n",
    "        return\n",
    "    \n",
    "    # Path to your folder containing menu images\n",
    "    IMAGE_FOLDER = './test_menu/'\n",
    "    \n",
    "    # Number of price categories (A, B, C, etc.)\n",
    "    NUM_CATEGORIES = 4\n",
    "    \n",
    "    print(\"===== MENU ITEM EXTRACTION AND CATEGORIZATION =====\")\n",
    "    print(f\"Processing menu images from: {IMAGE_FOLDER}\")\n",
    "    print(f\"Target number of price categories: {NUM_CATEGORIES}\")\n",
    "    \n",
    "    # Process menu images\n",
    "    categories, confidence_scores = process_menu_images(API_KEY, IMAGE_FOLDER, NUM_CATEGORIES)\n",
    "    \n",
    "    if categories:\n",
    "        # Calculate overall average confidence\n",
    "        avg_confidence = sum(confidence_scores.values())/len(confidence_scores)*100 if confidence_scores else 0\n",
    "        print(f\"\\nExtraction Complete - Average confidence score: {avg_confidence:.1f}%\")\n",
    "        \n",
    "        print(\"\\n========== MENU ITEMS BY PRICE CATEGORY ==========\")\n",
    "        for category, items in sorted(categories.items()):\n",
    "            if items:\n",
    "                category_min = min([price for _, price in items])\n",
    "                category_max = max([price for _, price in items])\n",
    "                print(f\"\\n----- Category {category} (${category_min:.2f} - ${category_max:.2f}) -----\")\n",
    "                print(f\"{len(items)} items:\")\n",
    "                \n",
    "                for item, price in sorted(items, key=lambda x: x[1], reverse=True):\n",
    "                    print(f\"  ${price:.2f} - {item}\")\n",
    "        \n",
    "        # Save categorized items to a file without confidence information\n",
    "        try:\n",
    "            with open(\"categorized_menu_items.txt\", \"w\") as f:\n",
    "                f.write(\"===== MENU ITEMS BY PRICE CATEGORY =====\\n\")\n",
    "                for category, items in sorted(categories.items()):\n",
    "                    if items:\n",
    "                        category_min = min([price for _, price in items])\n",
    "                        category_max = max([price for _, price in items])\n",
    "                        f.write(f\"\\n----- Category {category} (${category_min:.2f} - ${category_max:.2f}) -----\\n\")\n",
    "                        \n",
    "                        for item, price in sorted(items, key=lambda x: x[1], reverse=True):\n",
    "                            f.write(f\"  ${price:.2f} - {item}\\n\")\n",
    "            print(f\"\\nResults saved to categorized_menu_items.txt\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results to file: {e}\")\n",
    "    else:\n",
    "        print(\"No menu items found in the images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bundle Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"Suggested bundle price\": 400.35,\n",
      "    \"Number of diners\": 1,\n",
      "    \"Category Portions\": {\n",
      "      \"Category A\": 1,\n",
      "      \"Category B\": 1,\n",
      "      \"Category C\": 1,\n",
      "      \"Category D\": 1\n",
      "    },\n",
      "    \"Original bundle price\": 471.00,\n",
      "    \"Discount percentage\": 15.0,\n",
      "    \"Price per diner\": 400.35\n",
      "  },\n",
      "  {\n",
      "    \"Suggested bundle price\": 1026.08,\n",
      "    \"Number of diners\": 2,\n",
      "    \"Category Portions\": {\n",
      "      \"Category A\": 2,\n",
      "      \"Category B\": 2,\n",
      "      \"Category C\": 2,\n",
      "      \"Category D\": 2\n",
      "    },\n",
      "    \"Original bundle price\": 1166.00,\n",
      "    \"Discount percentage\": 12.0,\n",
      "    \"Price per diner\": 513.04\n",
      "  },\n",
      "  {\n",
      "    \"Suggested bundle price\": 1986.04,\n",
      "    \"Number of diners\": 4,\n",
      "    \"Category Portions\": {\n",
      "      \"Category A\": 3,\n",
      "      \"Category B\": 4,\n",
      "      \"Category C\": 4,\n",
      "      \"Category D\": 4\n",
      "    },\n",
      "    \"Original bundle price\": 2422.00,\n",
      "    \"Discount percentage\": 18.0,\n",
      "    \"Price per diner\": 496.51\n",
      "  },\n",
      "  {\n",
      "    \"Suggested bundle price\": 3025.28,\n",
      "    \"Number of diners\": 6,\n",
      "    \"Category Portions\": {\n",
      "      \"Category A\": 4,\n",
      "      \"Category B\": 6,\n",
      "      \"Category C\": 6,\n",
      "      \"Category D\": 6\n",
      "    },\n",
      "    \"Original bundle price\": 3781.60,\n",
      "    \"Discount percentage\": 20.0,\n",
      "    \"Price per diner\": 504.21\n",
      "  }\n",
      "]\n",
      "\n",
      "Parsing response as JSON...\n",
      "All 4 valid JSONs saved to menu_bundles.json\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def generate():\n",
    "    try:\n",
    "        client = genai.Client(\n",
    "            api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Gemini client: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if categorized_menu_items.txt exists\n",
    "    if not os.path.exists(\"./categorized_menu_items.txt\"):\n",
    "        print(\"Error: categorized_menu_items.txt file not found\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Read the file content\n",
    "        with open(\"./categorized_menu_items.txt\", \"r\") as file:\n",
    "            menu_content = file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading menu file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create prompt with the file content\n",
    "    prompt = f\"\"\"\n",
    "    Based on these categorised menu data:\n",
    "    \n",
    "    {menu_content}\n",
    "    \n",
    "    Please create 3-4 menu bundles for a varying number of diners (1-6 diners). Each bundle must include some items from each available menu category (A, B, C, and D if present).\n",
    "    \n",
    "    For each menu bundle, include:\n",
    "    1. The number of menu items from each category\n",
    "    2. The number of diners the bundle is designed for\n",
    "    3. The price per diner\n",
    "    4. A suggested discounted bundle price\n",
    "\n",
    "    Please follow this exact structure for each menu bundle:\n",
    "    Suggested bundle price:\n",
    "    Number of diners:\n",
    "    Category Portions:\n",
    "        Category A: [number of items]\n",
    "        Category B: [number of items]\n",
    "        Category C: [number of items]\n",
    "        Category D: [number of items]\n",
    "    Original bundle price:\n",
    "    Discount percentage:\n",
    "    Price per diner:\n",
    "    \n",
    "    Note: Include all four categories (A through D) in your response, even if some categories might have 0 items in certain bundles.\n",
    "    \"\"\"\n",
    "\n",
    "    model = \"gemini-2.5-pro-exp-03-25\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        system_instruction=[\n",
    "            types.Part.from_text(text=\"\"\"You are a menu bundle generator, and your task is to create several menu bundles based on a given input of menu categories. For each bundle:\n",
    "            \n",
    "1. Include items from all available categories (A, B, C, and D)\n",
    "2. Specify exactly how many portions from each category are included\n",
    "3. Calculate the original price based on the actual menu prices\n",
    "4. Apply a reasonable discount (10-20%)\n",
    "5. Calculate the per-person price\n",
    "            \n",
    "Always include all four categories (A through D) in your response structure, even if some categories have 0 items or don't exist in the input data.\"\"\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Collect the entire response\n",
    "    complete_response = \"\"\n",
    "    \n",
    "    try:\n",
    "        # Get the response generator\n",
    "        response_stream = client.models.generate_content_stream(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=generate_content_config,\n",
    "        )\n",
    "        \n",
    "        # Check if response is None\n",
    "        if response_stream is None:\n",
    "            print(\"Warning: API returned None for response stream\")\n",
    "            # Try non-streaming version as fallback\n",
    "            try:\n",
    "                print(\"Attempting to use non-streaming API as fallback...\")\n",
    "                response = client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=contents,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "                \n",
    "                if response and hasattr(response, 'text'):\n",
    "                    complete_response = response.text\n",
    "                elif response and hasattr(response, 'parts'):\n",
    "                    for part in response.parts:\n",
    "                        if hasattr(part, 'text') and part.text is not None:\n",
    "                            complete_response += part.text\n",
    "                else:\n",
    "                    print(\"Warning: Fallback response format is unexpected\")\n",
    "            except Exception as fallback_error:\n",
    "                print(f\"Fallback request also failed: {fallback_error}\")\n",
    "        else:\n",
    "            # Iterate through streaming response if it's not None\n",
    "            for chunk in response_stream:\n",
    "                # Handle the case where chunk.text might be None\n",
    "                # Get the text from different potential structures\n",
    "                chunk_text = \"\"\n",
    "                \n",
    "                # Try direct text property\n",
    "                if hasattr(chunk, 'text') and chunk.text is not None:\n",
    "                    chunk_text = chunk.text\n",
    "                # Try looking in parts\n",
    "                elif hasattr(chunk, 'parts') and chunk.parts:\n",
    "                    # Combine text from all parts\n",
    "                    for part in chunk.parts:\n",
    "                        if hasattr(part, 'text') and part.text is not None:\n",
    "                            chunk_text += part.text\n",
    "                # Try candidates structure\n",
    "                elif hasattr(chunk, 'candidates') and chunk.candidates:\n",
    "                    for candidate in chunk.candidates:\n",
    "                        if hasattr(candidate, 'content'):\n",
    "                            content = candidate.content\n",
    "                            if hasattr(content, 'parts'):\n",
    "                                for part in content.parts:\n",
    "                                    if hasattr(part, 'text') and part.text is not None:\n",
    "                                        chunk_text += part.text\n",
    "                \n",
    "                # Add to the complete response\n",
    "                complete_response += chunk_text\n",
    "                \n",
    "                # Print to console\n",
    "                if chunk_text:\n",
    "                    print(chunk_text, end=\"\")\n",
    "                else:\n",
    "                    print(\".\", end=\"\")  # Print a dot to indicate progress for empty chunks\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nError during generation: {e}\")\n",
    "        \n",
    "        # Last-ditch effort - try non-streaming API if streaming failed\n",
    "        if not complete_response:\n",
    "            try:\n",
    "                print(\"Attempting to use non-streaming API as final fallback...\")\n",
    "                response = client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=contents,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "                \n",
    "                if hasattr(response, 'text') and response.text:\n",
    "                    complete_response = response.text\n",
    "                    print(f\"Received {len(complete_response)} characters from fallback request\")\n",
    "            except Exception as fallback_error:\n",
    "                print(f\"Fallback request also failed: {fallback_error}\")\n",
    "    \n",
    "    # Parse and save as JSON\n",
    "    try:\n",
    "        print(\"\\n\\nParsing response as JSON...\")\n",
    "        \n",
    "        # Check if the response is empty\n",
    "        if not complete_response.strip():\n",
    "            raise ValueError(\"Empty response received from API\")\n",
    "            \n",
    "        # Save the raw response for debugging\n",
    "        with open(\"menu_bundles_raw.txt\", \"w\") as f:\n",
    "            f.write(complete_response)\n",
    "        \n",
    "        # Advanced JSON extraction - try to find valid JSON objects\n",
    "        import re\n",
    "        \n",
    "        # Look for JSON objects pattern\n",
    "        json_pattern = r'(\\{(?:[^{}]|(?:\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}))*\\})'\n",
    "        json_matches = re.findall(json_pattern, complete_response)\n",
    "        \n",
    "        all_valid_jsons = []\n",
    "        \n",
    "        if json_matches:\n",
    "            # Try each potential JSON match\n",
    "            potential_jsons = sorted(json_matches, key=len, reverse=True)\n",
    "            \n",
    "            for potential_json in potential_jsons:\n",
    "                try:\n",
    "                    json_data = json.loads(potential_json)\n",
    "                    all_valid_jsons.append(json_data)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        # Also try code blocks\n",
    "        code_block_matches = re.findall(r'```(?:json)?(.*?)```', complete_response, re.DOTALL)\n",
    "        for code_block in code_block_matches:\n",
    "            try:\n",
    "                json_data = json.loads(code_block.strip())\n",
    "                all_valid_jsons.append(json_data)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        # Save all valid JSONs to a single file\n",
    "        if all_valid_jsons:\n",
    "            with open(\"menu_bundles.json\", \"w\") as json_file:\n",
    "                json.dump(all_valid_jsons, json_file, indent=4)\n",
    "            print(f\"All {len(all_valid_jsons)} valid JSONs saved to menu_bundles.json\")\n",
    "        else:\n",
    "            print(\"No valid JSONs found in the response\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to parse response as JSON: {e}\")\n",
    "        print(\"Please check menu_bundles_raw.txt to see the actual response.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Excel Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 bundles in the JSON file:\n",
      "  1. Family Gathering Spread\n",
      "  2. Friends Feast Platter\n",
      "  3. Large Group Special\n",
      "  4. Cozy Couple Combo\n",
      "Setting Pack A in cells B3:C3 for bundle Family Gathering Spread\n",
      "Setting Pack B in cells D3:E3 for bundle Friends Feast Platter\n",
      "Setting Pack C in cells F3:G3 for bundle Large Group Special\n",
      "Setting Pack D in cells H3:I3 for bundle Cozy Couple Combo\n",
      "Setting price 2137 in cells B4:C4 for Pack A\n",
      "Setting price 1470 in cells D4:E4 for Pack B\n",
      "Setting price 3156 in cells F4:G4 for Pack C\n",
      "Setting price 897 in cells H4:I4 for Pack D\n",
      "Setting diners 6 in cells B5:C5 for Pack A\n",
      "Setting diners 4 in cells D5:E5 for Pack B\n",
      "Setting diners 8 in cells F5:G5 for Pack C\n",
      "Setting diners 2 in cells H5:I5 for Pack D\n",
      "Setting remarks in cells B6:C6 for Pack A\n",
      "Setting remarks in cells D6:E6 for Pack B\n",
      "Setting remarks in cells F6:G6 for Pack C\n",
      "Setting remarks in cells H6:I6 for Pack D\n",
      "Setting Category A = 3 in cells B8:C8 for Pack A\n",
      "Setting Category B = 6 in cells B9:C9 for Pack A\n",
      "Setting Category C = 3 in cells B10:C10 for Pack A\n",
      "Setting Category D = 6 in cells B11:C11 for Pack A\n",
      "Setting Category A = 2 in cells D8:E8 for Pack B\n",
      "Setting Category B = 4 in cells D9:E9 for Pack B\n",
      "Setting Category C = 2 in cells D10:E10 for Pack B\n",
      "Setting Category D = 4 in cells D11:E11 for Pack B\n",
      "Setting Category A = 4 in cells F8:G8 for Pack C\n",
      "Setting Category B = 8 in cells F9:G9 for Pack C\n",
      "Setting Category C = 4 in cells F10:G10 for Pack C\n",
      "Setting Category D = 8 in cells F11:G11 for Pack C\n",
      "Setting Category A = 1 in cells H8:I8 for Pack D\n",
      "Setting Category B = 2 in cells H9:I9 for Pack D\n",
      "Setting Category C = 1 in cells H10:I10 for Pack D\n",
      "Setting Category D = 2 in cells H11:I11 for Pack D\n",
      "Setting total 18 in cells B12:C12 for Pack A\n",
      "Setting total 12 in cells D12:E12 for Pack B\n",
      "Setting total 24 in cells F12:G12 for Pack C\n",
      "Setting total 6 in cells H12:I12 for Pack D\n",
      "Setting original price 2607 in cells B14:C14 for Pack A\n",
      "Setting original price 1671 in cells D14:E14 for Pack B\n",
      "Setting original price 3946 in cells F14:G14 for Pack C\n",
      "Setting original price 1056 in cells H14:I14 for Pack D\n",
      "Setting discount 18.00 in cells B15:C15 for Pack A\n",
      "Setting discount 12.00 in cells D15:E15 for Pack B\n",
      "Setting discount 20.00 in cells F15:G15 for Pack C\n",
      "Setting discount 15.00 in cells H15:I15 for Pack D\n",
      "Setting price per person 356.29 / Person in cells B16:C16 for Pack A\n",
      "Setting price per person 367.62 / Person in cells D16:E16 for Pack B\n",
      "Setting price per person 394.60 / Person in cells F16:G16 for Pack C\n",
      "Setting price per person 448.80 / Person in cells H16:I16 for Pack D\n",
      "Excel file 'HH_Proposal.xlsx' has been created successfully with all 4 bundles.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill, Font, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.cell.cell import MergedCell\n",
    "\n",
    "def create_hungry_hub_proposal(json_file='./menu_bundles.json', output_file='HH_Proposal.xlsx'):\n",
    "    \"\"\"\n",
    "    Creates an Excel file formatted according to the Hungry Hub Party Pack Proposal layout\n",
    "    using data from the menu_bundles.json file.\n",
    "    \n",
    "    Args:\n",
    "        json_file (str): Path to the JSON file containing menu bundle data\n",
    "        output_file (str): Path where the Excel file will be saved\n",
    "    \n",
    "    Returns:\n",
    "        str: Success message\n",
    "    \"\"\"\n",
    "    # Step 1: Read the JSON file\n",
    "    with open(json_file, 'r') as file:\n",
    "        menu_bundles = json.load(file)\n",
    "    \n",
    "    # Debug info - print the bundles found\n",
    "    print(f\"Found {len(menu_bundles)} bundles in the JSON file:\")\n",
    "    for i, bundle in enumerate(menu_bundles):\n",
    "        print(f\"  {i+1}. {bundle['bundle_name']}\")\n",
    "\n",
    "    # Step 2: Create an Excel workbook and add a sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    worksheet = workbook.active\n",
    "    worksheet.title = 'HH Proposal'\n",
    "\n",
    "    # Step 3: Define styles for different sections\n",
    "    red_fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "    light_yellow_fill = PatternFill(start_color=\"FFFFD4\", end_color=\"FFFFD4\", fill_type=\"solid\")\n",
    "    bright_yellow_fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "    white_font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
    "    bold_font = Font(bold=True)\n",
    "    center_aligned = Alignment(horizontal='center', vertical='center')\n",
    "    left_aligned = Alignment(horizontal='left', vertical='center')\n",
    "    border = Border(\n",
    "        left=Side(style='thin'),\n",
    "        right=Side(style='thin'),\n",
    "        top=Side(style='thin'),\n",
    "        bottom=Side(style='thin')\n",
    "    )\n",
    "\n",
    "    # Step 4: Create the header\n",
    "    worksheet.merge_cells('A1:I1')\n",
    "    header_cell = worksheet['A1']\n",
    "    header_cell.value = \"Hungry Hub PARTY PACK PROPOSAL\"\n",
    "    header_cell.fill = red_fill\n",
    "    header_cell.font = white_font\n",
    "    header_cell.alignment = center_aligned\n",
    "\n",
    "    # Step 5: Add restaurant name\n",
    "    worksheet['A2'] = \"Restaurant Name:\"\n",
    "    worksheet.merge_cells('B2:I2')\n",
    "    worksheet['B2'] = \"Lamu:n\"\n",
    "    worksheet['B2'].alignment = center_aligned\n",
    "\n",
    "    # Step 6: Add package names\n",
    "    worksheet['A3'] = \"Package Name:\"\n",
    "\n",
    "    # Map bundles to packs\n",
    "    pack_data = [\n",
    "        {\"name\": \"Pack A\", \"columns\": \"B:C\", \"bundle\": menu_bundles[0]},\n",
    "        {\"name\": \"Pack B\", \"columns\": \"D:E\", \"bundle\": menu_bundles[1]},\n",
    "        {\"name\": \"Pack C\", \"columns\": \"F:G\", \"bundle\": menu_bundles[2]},\n",
    "        {\"name\": \"Pack D\", \"columns\": \"H:I\", \"bundle\": menu_bundles[3]}\n",
    "    ]\n",
    "    \n",
    "    # Set pack names\n",
    "    for pack in pack_data:\n",
    "        cell_range = f\"{pack['columns'].split(':')[0]}3:{pack['columns'].split(':')[1]}3\"\n",
    "        worksheet.merge_cells(cell_range)\n",
    "        cell = worksheet[cell_range.split(':')[0]]\n",
    "        cell.value = pack['name']\n",
    "        cell.alignment = center_aligned\n",
    "        print(f\"Setting {pack['name']} in cells {cell_range} for bundle {pack['bundle']['bundle_name']}\")\n",
    "\n",
    "    # Step 7: Add HH Selling Price\n",
    "    worksheet['A4'] = \"HH Selling Price (NET)\"\n",
    "\n",
    "    # Using suggested_bundle_price from JSON\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        cell_range = f\"{col_start}4:{col_end}4\"\n",
    "        \n",
    "        worksheet.merge_cells(cell_range)\n",
    "        \n",
    "        # Convert price string to number\n",
    "        price_str = pack['bundle']['suggested_bundle_price']\n",
    "        price = int(float(price_str.replace('$', '').replace(',', '')))\n",
    "        \n",
    "        worksheet[col_start + '4'] = price\n",
    "        worksheet[col_start + '4'].alignment = center_aligned\n",
    "        worksheet[col_start + '4'].fill = light_yellow_fill\n",
    "        print(f\"Setting price {price} in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 8: Add Max Diners\n",
    "    worksheet['A5'] = \"Max Diners / Set\"\n",
    "\n",
    "    # Using number_of_diners from JSON\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        cell_range = f\"{col_start}5:{col_end}5\"\n",
    "        \n",
    "        worksheet.merge_cells(cell_range)\n",
    "        \n",
    "        # Get diners\n",
    "        diners = pack['bundle']['number_of_diners']\n",
    "        \n",
    "        worksheet[col_start + '5'] = diners\n",
    "        worksheet[col_start + '5'].alignment = center_aligned\n",
    "        worksheet[col_start + '5'].fill = light_yellow_fill\n",
    "        print(f\"Setting diners {diners} in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 9: Add Remarks\n",
    "    worksheet['A6'] = \"Remarks\"\n",
    "\n",
    "    # Same remarks for all packs\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        cell_range = f\"{col_start}6:{col_end}6\"\n",
    "        \n",
    "        worksheet.merge_cells(cell_range)\n",
    "        worksheet[col_start + '6'] = \"1 Water / Person\"\n",
    "        worksheet[col_start + '6'].alignment = center_aligned\n",
    "        print(f\"Setting remarks in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 10: Add Menu Section Header\n",
    "    worksheet.merge_cells('A7:I7')\n",
    "    menu_header = worksheet['A7']\n",
    "    menu_header.value = \"Menu Section (portions from each section) - See Menu In Next Sheet\"\n",
    "    menu_header.fill = red_fill\n",
    "    menu_header.font = white_font\n",
    "    menu_header.alignment = center_aligned\n",
    "\n",
    "    # Step 11: Add Group A, B, C, D and their values\n",
    "    group_rows = {\n",
    "        \"Category A\": 8,  # Group A - row 8\n",
    "        \"Category B\": 9,  # Group B - row 9 \n",
    "        \"Category C\": 10, # Group C - row 10\n",
    "        \"Category D\": 11  # Group D - row 11\n",
    "    }\n",
    "    \n",
    "    # Set group labels in column A\n",
    "    worksheet['A8'] = \"Group A\"\n",
    "    worksheet['A9'] = \"Group B\"\n",
    "    worksheet['A10'] = \"Group C\"\n",
    "    worksheet['A11'] = \"Group D\"\n",
    "    \n",
    "    # Using category_portions from JSON\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        \n",
    "        for category, row in group_rows.items():\n",
    "            cell_range = f\"{col_start}{row}:{col_end}{row}\"\n",
    "            worksheet.merge_cells(cell_range)\n",
    "            \n",
    "            # Get portion value from bundle\n",
    "            value = pack['bundle']['category_portions'].get(category, 0)\n",
    "            \n",
    "            worksheet[f\"{col_start}{row}\"] = value\n",
    "            worksheet[f\"{col_start}{row}\"].alignment = center_aligned\n",
    "            worksheet[f\"{col_start}{row}\"].fill = light_yellow_fill\n",
    "            print(f\"Setting {category} = {value} in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 12: Add Total Dishes\n",
    "    worksheet['A12'] = \"Total Dishes\"\n",
    "\n",
    "    # Calculate totals based on all categories\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        cell_range = f\"{col_start}12:{col_end}12\"\n",
    "        \n",
    "        worksheet.merge_cells(cell_range)\n",
    "        \n",
    "        # Sum all Categories A, B, C, D\n",
    "        total = sum(pack['bundle']['category_portions'].values())\n",
    "        \n",
    "        worksheet[f\"{col_start}12\"] = total\n",
    "        worksheet[f\"{col_start}12\"].alignment = center_aligned\n",
    "        print(f\"Setting total {total} in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 13: Add Average NET Selling Price Header\n",
    "    worksheet.merge_cells('A13:I13')\n",
    "    price_header = worksheet['A13']\n",
    "    price_header.value = \"Average NET Selling Price / Discounts\"\n",
    "    price_header.fill = red_fill\n",
    "    price_header.font = white_font\n",
    "    price_header.alignment = center_aligned\n",
    "\n",
    "    # Step 14: Add Average NET Selling Price\n",
    "    worksheet['A14'] = \"Average NET Selling Price\"\n",
    "\n",
    "    # Using original_bundle_price from JSON\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        cell_range = f\"{col_start}14:{col_end}14\"\n",
    "        \n",
    "        worksheet.merge_cells(cell_range)\n",
    "        \n",
    "        # Convert price string to number and round\n",
    "        price_str = pack['bundle']['original_bundle_price']\n",
    "        price = round(float(price_str.replace('$', '').replace(',', '')))\n",
    "        \n",
    "        worksheet[col_start + '14'] = price\n",
    "        worksheet[col_start + '14'].alignment = center_aligned\n",
    "        print(f\"Setting original price {price} in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 15: Add Average Discount\n",
    "    worksheet['A15'] = \"Average Discount\"\n",
    "\n",
    "    # Using discount_percentage from JSON\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        cell_range = f\"{col_start}15:{col_end}15\"\n",
    "        \n",
    "        worksheet.merge_cells(cell_range)\n",
    "        \n",
    "        discount = pack['bundle']['discount_percentage']\n",
    "        \n",
    "        worksheet[col_start + '15'] = discount\n",
    "        worksheet[col_start + '15'].alignment = center_aligned\n",
    "        print(f\"Setting discount {discount} in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 16: Add Price Per Person row\n",
    "    worksheet['A16'] = \"Net Price\"\n",
    "\n",
    "    # Add price per person for each bundle\n",
    "    for pack in pack_data:\n",
    "        col_start = pack['columns'].split(':')[0]\n",
    "        col_end = pack['columns'].split(':')[1]\n",
    "        cell_range = f\"{col_start}16:{col_end}16\"\n",
    "        \n",
    "        worksheet.merge_cells(cell_range)\n",
    "        \n",
    "        # Format as \"XXX / Person\"\n",
    "        price_str = pack['bundle']['price_per_diner']\n",
    "        price = price_str.replace('$', '')\n",
    "        per_person = f\"{price} / Person\"\n",
    "        \n",
    "        worksheet[col_start + '16'] = per_person\n",
    "        worksheet[col_start + '16'].alignment = center_aligned\n",
    "        worksheet[col_start + '16'].fill = bright_yellow_fill\n",
    "        print(f\"Setting price per person {per_person} in cells {cell_range} for {pack['name']}\")\n",
    "\n",
    "    # Step 17: Add adjustment rows\n",
    "    worksheet['A17'] = \"You can Adjust\"\n",
    "    worksheet['A18'] = \"Don't Adjust (Formula)\"\n",
    "\n",
    "    # Step 18: Apply borders to all cells\n",
    "    for row in range(1, 19):\n",
    "        for col in range(1, 10):\n",
    "            cell_coord = f'{get_column_letter(col)}{row}'\n",
    "            cell = worksheet[cell_coord]\n",
    "            \n",
    "            # Only apply operations to non-merged cells\n",
    "            if not isinstance(cell, MergedCell):\n",
    "                cell.border = border\n",
    "\n",
    "    # Step 19: Adjust column widths\n",
    "    for col in range(1, 10):\n",
    "        worksheet.column_dimensions[get_column_letter(col)].width = 15\n",
    "\n",
    "    # Step 20: Save the workbook\n",
    "    workbook.save(output_file)\n",
    "    \n",
    "    return f\"Excel file '{output_file}' has been created successfully with all {len(pack_data)} bundles.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the function to create the Excel file\n",
    "    result = create_hungry_hub_proposal()\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-cloud-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
